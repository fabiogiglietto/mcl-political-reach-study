{
 "nbformat_minor": 5,
 "cells": [
  {
   "execution_count": null,
   "metadata": {},
   "source": "# =============================================================================\n#\n# Meta Content Library API: Multi-List Query with Provenance Tracking\n# MCL 6.0 VERSION\n#\n# PURPOSE: Query multiple producer lists, track which list(s) each post came\n#          from, deduplicate producers, and use smart batching to respect\n#          the 100K results-per-query limit.\n#\n# KEY FEATURES:\n# 1. Uses $estimated_results (NOT $summary$approximate_results)\n# 2. Adds flush.console() after every cat() for Jupyter notebook output\n# 3. Adds name, description, mode=SNAPSHOT to all queries\n# 4. Creates a collection for organizing queries\n# 5. Uses client$get_async_job() and job methods\n# 6. Correct quota limit: 500K per 7-day rolling window\n# 7. Uses integer literals with L suffix\n# 8. Processes ALL surfaces with smart batching\n#\n# =============================================================================\n\n# 1. LOAD LIBRARIES\n# =============================================================================\nlibrary(reticulate)\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Load shared utilities and configuration\nsource(\"scripts/utils.R\")\nconfig <- load_config(\"IT\")\n\n# 2. INITIALIZE API CLIENT\n# =============================================================================\ncat(\"Initializing Meta Content Library API client (MCL 6.0)...\\n\")\nflush.console()\n\nclient <- import(\"metacontentlibraryapi\")$MetaContentLibraryAPIClient\nclient$set_default_version(client$LATEST_VERSION)\n\ncat(\"âœ“ API client initialized successfully\\n\\n\")\nflush.console()\n\n# 3. CONFIGURATION\n# =============================================================================\n\n# FACEBOOK POST FIELDS CONFIGURATION\nSELECTED_POST_FIELDS <- c(\n  \"id\",\n  \"creation_time\",\n  \"text\",\n  \"statistics\",\n  \"content_type\",\n  \"surface\",\n  \"post_owner\",\n  \"is_verified\",\n  \"is_branded_content\"\n)\n\nAPI_FIELDS_STRING <- paste(SELECTED_POST_FIELDS, collapse = \",\")\n\n# ============================================================================\n# DEFINE PRODUCER LISTS WITH METADATA\n# ----------------------------------------------------------------------------\n# Producer lists are now loaded from the configuration file (config/IT.yaml)\n# instead of being hardcoded here. This ensures consistency across all\n# notebooks and scripts in the project.\n# ============================================================================\nPRODUCER_LISTS <- list(\n  list(\n    list_id = config$producer_lists$mps_all,\n    list_name = \"MPs_All\",\n    description = \"All Members of Parliament\"\n  ),\n  list(\n    list_id = config$producer_lists$mps_reelected,\n    list_name = \"MPs_Reelected\",\n    description = \"Reelected Members of Parliament\"\n  ),\n  list(\n    list_id = config$producer_lists$prominent_politicians,\n    list_name = \"Prominent_Politicians\",\n    description = \"Prominent Politicians\"\n  ),\n  list(\n    list_id = config$producer_lists$extremists_cluster1,\n    list_name = \"Extremists_Cluster1\",\n    description = \"Extremists Cluster 1\"\n  ),\n  list(\n    list_id = config$producer_lists$extremists_cluster2,\n    list_name = \"Extremists_Cluster2\",\n    description = \"Extremists Cluster 2\"\n  )\n)\n\n# QUERY PARAMETERS - Loaded from configuration\nSTART_DATE <- format(config$study_period$start_date, \"%Y-%m-%d\")\nEND_DATE <- format(config$study_period$end_date, \"%Y-%m-%d\")\nMAX_RESULTS_PER_BATCH <- 90000L  # Safety margin below 100K API limit (INTEGER!)\n\n# QUOTA CHECK CONFIGURATION\nENABLE_QUOTA_CHECKS <- TRUE\n# MCL 6.0: 500,000 records per 7-day rolling window\nASSUMED_AVAILABLE_QUOTA <- 500000L\n\n# PROJECT DOCUMENTATION (CRITICAL for reproducibility)\nPROJECT_NAME <- \"Political Content Analysis\"  # Update for your project\nPROJECT_DESCRIPTION <- paste0(\n  \"PURPOSE: Multi-list analysis of political content on Facebook. \",\n  \"SCOPE: Posts from defined producer lists. \",\n  \"DATE RANGE: \", START_DATE, \" to \", END_DATE, \". \",\n  \"METHODOLOGY: Batch queries with provenance tracking. \",\n  \"PI: [Your Name], IRB: [Your IRB Number]\"\n)\n\n# Create output directory\nOUTPUT_DIR <- \"data_download_output\"\nif (!dir.exists(OUTPUT_DIR)) {\n  dir.create(OUTPUT_DIR, recursive = TRUE)\n}",
   "id": "config-cell",
   "cell_type": "code",
   "outputs": []
  },
  {
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 4. UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "#' Check current API quota - CRITICAL for planning\n",
    "#' MCL 6.0: Uses /budgets endpoint\n",
    "#' @return List with available quota, usage info, and over_quota flag\n",
    "mcl_check_quota <- function() {\n",
    "  cat(\"Checking API query budget...\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  tryCatch({\n",
    "    response <- client$get(path = \"budgets\")\n",
    "    budgets <- fromJSON(response$text, flatten = TRUE)\n",
    "    \n",
    "    # Extract query budget info\n",
    "    queries <- budgets$queries\n",
    "    queries_used <- as.numeric(queries$total_usage)\n",
    "    queries_limit <- as.numeric(queries$max_usage_limit)\n",
    "    queries_avail <- queries_limit - queries_used\n",
    "    in_progress <- as.numeric(queries$preallocated_rows_for_running_queries)\n",
    "    usage_pct <- (queries_used / queries_limit) * 100\n",
    "    \n",
    "    cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "    cat(\"ğŸ“Š QUOTA STATUS:\\n\")\n",
    "    cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    cat(sprintf(\"Used:      %12s / %s records (%.1f%%)\\n\",\n",
    "                format(queries_used, big.mark = \",\"),\n",
    "                format(queries_limit, big.mark = \",\"),\n",
    "                usage_pct))\n",
    "    flush.console()\n",
    "    \n",
    "    cat(sprintf(\"Available: %12s records\\n\",\n",
    "                format(queries_avail, big.mark = \",\")))\n",
    "    flush.console()\n",
    "    \n",
    "    if (in_progress > 0) {\n",
    "      cat(sprintf(\"In Progress: %10s records\\n\",\n",
    "                  format(in_progress, big.mark = \",\")))\n",
    "      flush.console()\n",
    "    }\n",
    "    \n",
    "    cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    if (queries_avail <= 0) {\n",
    "      cat(\"âš ï¸  WARNING: QUERY QUOTA EXCEEDED\\n\")\n",
    "      cat(\"Wait for quota to reset (7-day rolling window)\\n\\n\")\n",
    "      flush.console()\n",
    "    }\n",
    "    \n",
    "    return(list(\n",
    "      available = queries_avail,\n",
    "      total_usage = queries_used,\n",
    "      max_limit = queries_limit,\n",
    "      in_progress = in_progress,\n",
    "      usage_pct = usage_pct,\n",
    "      over_quota = (queries_avail <= 0)\n",
    "    ))\n",
    "    \n",
    "  }, error = function(e) {\n",
    "    cat(\"âŒ ERROR: Cannot check quota -\", e$message, \"\\n\\n\")\n",
    "    flush.console()\n",
    "    stop(\"Quota check failed: \", e$message)\n",
    "  })\n",
    "}\n",
    "\n",
    "#' Get estimate for query - MUST use $estimated_results\n",
    "#' MCL 6.0: Uses GET /facebook/posts/estimate endpoint\n",
    "#' @param surface_ids List of surface IDs to query\n",
    "#' @param start_date Start date (YYYY-MM-DD)\n",
    "#' @param end_date End date (YYYY-MM-DD)\n",
    "#' @return List with estimated_results, expected_complete, and over_limit flag\n",
    "mcl_get_estimate <- function(surface_ids, start_date, end_date) {\n",
    "  \n",
    "  params <- list(\n",
    "    surface_ids = as.list(as.character(surface_ids)),\n",
    "    since = as.character(start_date),\n",
    "    until = as.character(end_date)\n",
    "  )\n",
    "  \n",
    "  tryCatch({\n",
    "    response <- client$get(path = \"facebook/posts/estimate\", params = params)\n",
    "    estimate_data <- fromJSON(response$text, flatten = TRUE)\n",
    "    \n",
    "    # CRITICAL: Use $estimated_results (the ONLY correct field!)\n",
    "    count <- estimate_data$estimated_results\n",
    "    complete <- estimate_data$expected_complete\n",
    "    \n",
    "    if (is.null(count) || length(count) == 0) {\n",
    "      return(list(estimated_results = NA_real_, expected_complete = NA, over_limit = NA))\n",
    "    }\n",
    "    \n",
    "    return(list(\n",
    "      estimated_results = as.numeric(count),\n",
    "      expected_complete = isTRUE(complete),\n",
    "      over_limit = !isTRUE(complete)\n",
    "    ))\n",
    "    \n",
    "  }, error = function(e) {\n",
    "    return(list(estimated_results = NA_real_, expected_complete = NA, over_limit = NA))\n",
    "  })\n",
    "}\n",
    "\n",
    "#' Safely retrieve producer list with validation\n",
    "#' @param list_name Name of the list (for logging)\n",
    "#' @param list_id ID of the producer list\n",
    "#' @return Character vector of surface IDs\n",
    "mcl_get_producer_list <- function(list_name, list_id) {\n",
    "  cat(\"ğŸ“‹ Retrieving producer list '\", list_name, \"' (\", list_id, \")...\\n\", sep = \"\")\n",
    "  flush.console()\n",
    "  \n",
    "  tryCatch({\n",
    "    response <- client$get(path = paste0(\"lists/producers/\", list_id))\n",
    "    producers_json <- fromJSON(response$text, flatten = TRUE)\n",
    "    \n",
    "    producer_data <- producers_json$producers\n",
    "    \n",
    "    if (is.null(producer_data) || nrow(producer_data) == 0) {\n",
    "      cat(\"âš ï¸  No producers found in list '\", list_name, \"'\\n\", sep = \"\")\n",
    "      flush.console()\n",
    "      return(character(0))\n",
    "    }\n",
    "    \n",
    "    all_ids <- as.character(producer_data$id)\n",
    "    valid_ids <- all_ids[!is.na(all_ids) & nchar(all_ids) > 0]\n",
    "    \n",
    "    cat(\"âœ… Retrieved\", length(valid_ids), \"producer IDs from '\", list_name, \"'\\n\", sep = \"\")\n",
    "    flush.console()\n",
    "    \n",
    "    return(valid_ids)\n",
    "    \n",
    "  }, error = function(e) {\n",
    "    cat(\"âŒ ERROR: Failed to retrieve producer list '\", list_name, \"' - \",\n",
    "        e$message, \"\\n\", sep = \"\")\n",
    "    flush.console()\n",
    "    return(character(0))\n",
    "  })\n",
    "}\n",
    "\n",
    "#' Create a collection for organizing queries\n",
    "#' @param name Collection name\n",
    "#' @param description Collection description\n",
    "#' @param set_as_default Whether to set as default collection\n",
    "#' @return Collection ID or NULL on error\n",
    "mcl_create_collection <- function(name, description, set_as_default = TRUE) {\n",
    "  cat(\"Creating collection:\", name, \"...\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  tryCatch({\n",
    "    response <- client$post(\n",
    "      path = \"async/collections\",\n",
    "      body = list(\n",
    "        name = name,\n",
    "        description = description,\n",
    "        default = set_as_default\n",
    "      )\n",
    "    )\n",
    "    \n",
    "    collection_data <- fromJSON(response$text, flatten = TRUE)\n",
    "    collection_id <- collection_data$id\n",
    "    \n",
    "    cat(\"âœ… Collection created successfully\\n\")\n",
    "    cat(\"  Collection ID:\", collection_id, \"\\n\")\n",
    "    cat(\"  Name:\", name, \"\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    if (set_as_default) {\n",
    "      cat(\"  Set as default: Yes (new queries will go here)\\n\")\n",
    "      flush.console()\n",
    "    }\n",
    "    cat(\"\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    return(collection_id)\n",
    "    \n",
    "  }, error = function(e) {\n",
    "    cat(\"âŒ Error creating collection:\", e$message, \"\\n\")\n",
    "    flush.console()\n",
    "    return(NULL)\n",
    "  })\n",
    "}"
   ],
   "id": "utility-functions-1",
   "cell_type": "code",
   "outputs": []
  },
  {
   "execution_count": null,
   "metadata": {},
   "source": [
    "#' Create smart batches based on estimated results\n",
    "#' @param surface_ids Vector of surface IDs\n",
    "#' @param start_date Start date\n",
    "#' @param end_date End date\n",
    "#' @param max_results Maximum results per batch (default 90000)\n",
    "#' @return List of batches with surface_ids and estimated_results\n",
    "mcl_create_smart_batches <- function(surface_ids, start_date, end_date, max_results = 90000L) {\n",
    "  \n",
    "  cat(\"\\n\")\n",
    "  cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "  cat(\"CREATING SMART BATCHES (Result-based, not count-based)\\n\")\n",
    "  cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  total_surfaces <- length(surface_ids)\n",
    "  cat(\"Total surface IDs:\", total_surfaces, \"\\n\")\n",
    "  cat(\"Max results per batch:\", format(max_results, big.mark = \",\"), \"\\n\")\n",
    "  cat(\"(Safety margin: 10K below API's 100K limit)\\n\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  # Phase 1: Sample estimation to gauge activity levels\n",
    "  cat(\"Phase 1: Estimating sample surfaces to gauge activity levels...\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  sample_size <- min(20L, total_surfaces)\n",
    "  individual_estimates <- numeric(sample_size)\n",
    "  \n",
    "  for (i in 1:sample_size) {\n",
    "    sid <- surface_ids[i]\n",
    "    cat(\"  Estimating\", i, \"/\", sample_size, \":\", substr(sid, 1, 20), \"...\")\n",
    "    flush.console()\n",
    "    \n",
    "    estimate <- mcl_get_estimate(list(sid), start_date, end_date)\n",
    "    \n",
    "    if (!is.na(estimate$estimated_results)) {\n",
    "      individual_estimates[i] <- estimate$estimated_results\n",
    "      cat(\" \", format(estimate$estimated_results, big.mark = \",\"), \"posts\\n\")\n",
    "    } else {\n",
    "      individual_estimates[i] <- 0\n",
    "      cat(\" 0 posts (or error)\\n\")\n",
    "    }\n",
    "    flush.console()\n",
    "  }\n",
    "  \n",
    "  # Calculate average posts per surface\n",
    "  avg_per_surface <- mean(individual_estimates)\n",
    "  cat(\"\\nAverage posts per surface:\", format(round(avg_per_surface), big.mark = \",\"), \"\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  # Determine initial batch size based on average\n",
    "  if (avg_per_surface > 0) {\n",
    "    initial_batch_size <- floor(max_results / avg_per_surface)\n",
    "    initial_batch_size <- max(1L, min(initial_batch_size, 50L))\n",
    "  } else {\n",
    "    initial_batch_size <- 25L\n",
    "  }\n",
    "  \n",
    "  cat(\"Initial batch size:\", initial_batch_size, \"surface IDs\\n\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  # Phase 2: Create and verify batches\n",
    "  cat(\"Phase 2: Creating and verifying batches...\\n\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  batches <- list()\n",
    "  batch_num <- 1L\n",
    "  processed_count <- 0L\n",
    "  \n",
    "  while (processed_count < total_surfaces) {\n",
    "    \n",
    "    remaining_surfaces <- surface_ids[(processed_count + 1L):total_surfaces]\n",
    "    remaining_count <- length(remaining_surfaces)\n",
    "    \n",
    "    cat(\"  --- Starting batch\", batch_num, \"---\\n\")\n",
    "    cat(\"  Surfaces remaining:\", remaining_count, \"\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    test_size <- min(initial_batch_size, remaining_count)\n",
    "    test_batch <- remaining_surfaces[1:test_size]\n",
    "    cat(\"  Testing with\", test_size, \"surfaces...\")\n",
    "    flush.console()\n",
    "    \n",
    "    test_estimate <- mcl_get_estimate(test_batch, start_date, end_date)\n",
    "    \n",
    "    if (is.na(test_estimate$estimated_results)) {\n",
    "      cat(\" estimate failed, trying smaller batch\\n\")\n",
    "      flush.console()\n",
    "      test_size <- 1L\n",
    "      test_batch <- remaining_surfaces[1]\n",
    "      test_estimate <- mcl_get_estimate(test_batch, start_date, end_date)\n",
    "      \n",
    "      if (is.na(test_estimate$estimated_results)) {\n",
    "        cat(\"  âš ï¸  Cannot estimate even single surface, skipping\\n\")\n",
    "        flush.console()\n",
    "        processed_count <- processed_count + 1L\n",
    "        next\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    cat(\" \", format(test_estimate$estimated_results, big.mark = \",\"), \"results\")\n",
    "    flush.console()\n",
    "    \n",
    "    if (test_estimate$estimated_results <= max_results) {\n",
    "      cat(\" âœ… OK\\n\")\n",
    "      flush.console()\n",
    "      \n",
    "      current_batch <- test_batch\n",
    "      current_estimate <- test_estimate$estimated_results\n",
    "      current_size <- test_size\n",
    "      \n",
    "      # Try adding more surfaces\n",
    "      while (current_size < remaining_count) {\n",
    "        next_size <- current_size + 1L\n",
    "        next_batch <- remaining_surfaces[1:next_size]\n",
    "        \n",
    "        cat(\"  Testing with\", next_size, \"surfaces...\")\n",
    "        flush.console()\n",
    "        \n",
    "        next_estimate <- mcl_get_estimate(next_batch, start_date, end_date)\n",
    "        \n",
    "        if (is.na(next_estimate$estimated_results)) {\n",
    "          cat(\" estimate failed, keeping current batch\\n\")\n",
    "          flush.console()\n",
    "          break\n",
    "        }\n",
    "        \n",
    "        cat(\" \", format(next_estimate$estimated_results, big.mark = \",\"), \"results\")\n",
    "        flush.console()\n",
    "        \n",
    "        if (next_estimate$estimated_results <= max_results) {\n",
    "          cat(\" âœ… OK\\n\")\n",
    "          flush.console()\n",
    "          current_batch <- next_batch\n",
    "          current_estimate <- next_estimate$estimated_results\n",
    "          current_size <- next_size\n",
    "        } else {\n",
    "          cat(\" âŒ EXCEEDS LIMIT - stopping growth\\n\")\n",
    "          flush.console()\n",
    "          break\n",
    "        }\n",
    "      }\n",
    "      \n",
    "      batches[[batch_num]] <- list(\n",
    "        surface_ids = current_batch,\n",
    "        estimated_results = current_estimate\n",
    "      )\n",
    "      cat(\"  âœ… Saving batch\", batch_num, \"with\", current_size, \"surfaces,\",\n",
    "          format(current_estimate, big.mark = \",\"), \"estimated results\\n\\n\")\n",
    "      flush.console()\n",
    "      \n",
    "      processed_count <- processed_count + current_size\n",
    "      batch_num <- batch_num + 1L\n",
    "      \n",
    "    } else {\n",
    "      cat(\" âŒ EXCEEDS LIMIT\\n\")\n",
    "      flush.console()\n",
    "      \n",
    "      if (test_size == 1L) {\n",
    "        cat(\"  âš ï¸  Single surface exceeds limit - including anyway\\n\")\n",
    "        flush.console()\n",
    "        \n",
    "        batches[[batch_num]] <- list(\n",
    "          surface_ids = test_batch,\n",
    "          estimated_results = test_estimate$estimated_results\n",
    "        )\n",
    "        cat(\"  âœ… Saving batch\", batch_num, \"with 1 surface,\",\n",
    "            format(test_estimate$estimated_results, big.mark = \",\"), \"estimated results\\n\\n\")\n",
    "        flush.console()\n",
    "        \n",
    "        processed_count <- processed_count + 1L\n",
    "        batch_num <- batch_num + 1L\n",
    "        \n",
    "      } else {\n",
    "        # Binary search for optimal size\n",
    "        cat(\"  Searching for optimal batch size...\\n\")\n",
    "        flush.console()\n",
    "        \n",
    "        low <- 1L\n",
    "        high <- test_size - 1L\n",
    "        best_batch <- NULL\n",
    "        best_estimate <- 0\n",
    "        best_size <- 0L\n",
    "        \n",
    "        while (low <= high) {\n",
    "          mid <- (low + high) %/% 2L\n",
    "          mid_batch <- remaining_surfaces[1:mid]\n",
    "          \n",
    "          cat(\"    Testing\", mid, \"surfaces...\")\n",
    "          flush.console()\n",
    "          \n",
    "          mid_estimate <- mcl_get_estimate(mid_batch, start_date, end_date)\n",
    "          \n",
    "          if (is.na(mid_estimate$estimated_results)) {\n",
    "            cat(\" estimate failed\\n\")\n",
    "            flush.console()\n",
    "            high <- mid - 1L\n",
    "            next\n",
    "          }\n",
    "          \n",
    "          cat(\" \", format(mid_estimate$estimated_results, big.mark = \",\"), \"results\")\n",
    "          flush.console()\n",
    "          \n",
    "          if (mid_estimate$estimated_results <= max_results) {\n",
    "            cat(\" âœ… OK\\n\")\n",
    "            flush.console()\n",
    "            best_batch <- mid_batch\n",
    "            best_estimate <- mid_estimate$estimated_results\n",
    "            best_size <- mid\n",
    "            low <- mid + 1L\n",
    "          } else {\n",
    "            cat(\" âŒ too large\\n\")\n",
    "            flush.console()\n",
    "            high <- mid - 1L\n",
    "          }\n",
    "        }\n",
    "        \n",
    "        if (!is.null(best_batch)) {\n",
    "          batches[[batch_num]] <- list(\n",
    "            surface_ids = best_batch,\n",
    "            estimated_results = best_estimate\n",
    "          )\n",
    "          cat(\"  âœ… Saving batch\", batch_num, \"with\", best_size, \"surfaces,\",\n",
    "              format(best_estimate, big.mark = \",\"), \"estimated results\\n\\n\")\n",
    "          flush.console()\n",
    "          \n",
    "          processed_count <- processed_count + best_size\n",
    "          batch_num <- batch_num + 1L\n",
    "        } else {\n",
    "          cat(\"  âš ï¸  Could not create valid batch, skipping surface\\n\\n\")\n",
    "          flush.console()\n",
    "          processed_count <- processed_count + 1L\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    cat(\"  Progress:\", processed_count, \"/\", total_surfaces, \"surfaces processed\\n\\n\")\n",
    "    flush.console()\n",
    "  }\n",
    "  \n",
    "  # Summary\n",
    "  cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "  cat(\"BATCH CREATION COMPLETE\\n\")\n",
    "  cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  total_batched_surfaces <- sum(sapply(batches, function(b) length(b$surface_ids)))\n",
    "  total_estimated_results <- sum(sapply(batches, function(b) b$estimated_results))\n",
    "  \n",
    "  cat(\"Total batches created:\", length(batches), \"\\n\")\n",
    "  cat(\"Total surface IDs processed:\", total_batched_surfaces, \"/\", total_surfaces, \"\\n\")\n",
    "  cat(\"Total estimated results:\", format(total_estimated_results, big.mark = \",\"), \"\\n\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  if (total_batched_surfaces != total_surfaces) {\n",
    "    cat(\"âš ï¸  WARNING: Not all surfaces were batched!\\n\")\n",
    "    cat(\"   Expected:\", total_surfaces, \"\\n\")\n",
    "    cat(\"   Actual:\", total_batched_surfaces, \"\\n\")\n",
    "    cat(\"   Missing:\", total_surfaces - total_batched_surfaces, \"\\n\\n\")\n",
    "    flush.console()\n",
    "  } else {\n",
    "    cat(\"âœ… All surfaces successfully batched!\\n\\n\")\n",
    "    flush.console()\n",
    "  }\n",
    "  \n",
    "  cat(\"Batch details:\\n\")\n",
    "  for (i in seq_along(batches)) {\n",
    "    cat(\"  Batch\", i, \":\",\n",
    "        length(batches[[i]]$surface_ids), \"surfaces,\",\n",
    "        format(batches[[i]]$estimated_results, big.mark = \",\"), \"estimated results\\n\")\n",
    "  }\n",
    "  cat(\"\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  return(batches)\n",
    "}"
   ],
   "id": "smart-batches",
   "cell_type": "code",
   "outputs": []
  },
  {
   "execution_count": null,
   "metadata": {},
   "source": [
    "#' Execute async search with proper job handling\n",
    "#' @param surface_ids List of surface IDs\n",
    "#' @param start_date Start date\n",
    "#' @param end_date End date\n",
    "#' @param fields Fields string\n",
    "#' @param name Query name (REQUIRED for reproducibility)\n",
    "#' @param description Query description (REQUIRED for reproducibility)\n",
    "#' @param collection_id Collection ID to assign query to\n",
    "#' @param output_dir Output directory for results\n",
    "#' @return List with data, job_id, query_id, status\n",
    "mcl_execute_async_search <- function(surface_ids,\n",
    "                                     start_date,\n",
    "                                     end_date,\n",
    "                                     fields,\n",
    "                                     name,\n",
    "                                     description,\n",
    "                                     collection_id = NULL,\n",
    "                                     output_dir = \"mcl_results\") {\n",
    "  \n",
    "  cat(\"ğŸš€ Submitting async search for\", length(surface_ids), \"surfaces...\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  if (!dir.exists(output_dir)) {\n",
    "    dir.create(output_dir, recursive = TRUE)\n",
    "  }\n",
    "  \n",
    "  params <- list(\n",
    "    surface_ids = as.list(as.character(surface_ids)),\n",
    "    since = as.character(start_date),\n",
    "    until = as.character(end_date),\n",
    "    fields = fields,\n",
    "    sort = \"newest_to_oldest\",\n",
    "    mode = \"SNAPSHOT\",\n",
    "    name = name,\n",
    "    description = description\n",
    "  )\n",
    "  \n",
    "  tryCatch({\n",
    "    response <- client$post(path = \"facebook/posts/job\", params = params)\n",
    "    initial_response <- fromJSON(response$text, flatten = TRUE)\n",
    "    \n",
    "    job_id <- initial_response$id\n",
    "    query_id <- initial_response$query_id\n",
    "    \n",
    "    cat(\"  Job ID:\", job_id, \"\\n\")\n",
    "    cat(\"  Query ID:\", query_id, \"\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    if (!is.null(collection_id)) {\n",
    "      cat(\"  Assigning to collection...\\n\")\n",
    "      flush.console()\n",
    "      \n",
    "      client$post(\n",
    "        path = paste0(\"async/queries/\", query_id),\n",
    "        body = list(collection_id = collection_id)\n",
    "      )\n",
    "      cat(\"  âœ… Assigned to collection:\", collection_id, \"\\n\")\n",
    "      flush.console()\n",
    "    }\n",
    "    \n",
    "    cat(\"  Monitoring job status...\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    job <- client$get_async_job(job_id = job_id)\n",
    "    status <- job$get_status()\n",
    "    start_time <- Sys.time()\n",
    "    \n",
    "    while (status != \"COMPLETE\") {\n",
    "      Sys.sleep(10)\n",
    "      status <- job$get_status()\n",
    "      elapsed <- round(as.numeric(difftime(Sys.time(), start_time, units = \"mins\")), 1)\n",
    "      \n",
    "      cat(\"  Status:\", status, \"(\", elapsed, \"min elapsed)\\n\")\n",
    "      flush.console()\n",
    "      \n",
    "      if (status == \"FAILED\") {\n",
    "        cat(\"  âŒ Job failed!\\n\")\n",
    "        flush.console()\n",
    "        return(list(data = NULL, job_id = job_id, query_id = query_id, status = \"FAILED\"))\n",
    "      }\n",
    "      \n",
    "      if (elapsed > 60) {\n",
    "        cat(\"  âŒ Timeout: Job took longer than 60 minutes\\n\")\n",
    "        flush.console()\n",
    "        return(list(data = NULL, job_id = job_id, query_id = query_id, status = \"TIMEOUT\"))\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    cat(\"  âœ… Job complete!\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    filename <- paste0(\"job_\", job_id, \".json\")\n",
    "    cat(\"  ğŸ“¥ Saving results to file...\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    job$write_data_to_file(directory = output_dir, filename = filename)\n",
    "    \n",
    "    filepath <- file.path(output_dir, filename)\n",
    "    cat(\"  ğŸ“– Reading data from file...\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    if (file.exists(filepath)) {\n",
    "      query_data <- fromJSON(filepath, flatten = TRUE)\n",
    "      \n",
    "      if (!is.data.frame(query_data)) {\n",
    "        query_data <- tryCatch({\n",
    "          as.data.frame(query_data, stringsAsFactors = FALSE)\n",
    "        }, error = function(e) {\n",
    "          bind_rows(query_data)\n",
    "        })\n",
    "      }\n",
    "      \n",
    "      if (is.data.frame(query_data) && nrow(query_data) > 0) {\n",
    "        cat(\"  âœ… Retrieved\", format(nrow(query_data), big.mark = \",\"), \"records\\n\")\n",
    "        flush.console()\n",
    "        \n",
    "        return(list(\n",
    "          data = query_data,\n",
    "          job_id = job_id,\n",
    "          query_id = query_id,\n",
    "          collection_id = collection_id,\n",
    "          status = \"COMPLETE\"\n",
    "        ))\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    cat(\"  âš ï¸  No data returned\\n\")\n",
    "    flush.console()\n",
    "    return(list(data = NULL, job_id = job_id, query_id = query_id, status = \"EMPTY\"))\n",
    "    \n",
    "  }, error = function(e) {\n",
    "    cat(\"  âŒ ERROR:\", e$message, \"\\n\")\n",
    "    flush.console()\n",
    "    return(list(data = NULL, job_id = NA, query_id = NA, status = \"ERROR\", error = e$message))\n",
    "  })\n",
    "}"
   ],
   "id": "async-search",
   "cell_type": "code",
   "outputs": []
  },
  {
   "execution_count": null,
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 5. MAIN EXECUTION WORKFLOW\n",
    "# =============================================================================\n",
    "\n",
    "cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "cat(\"MULTI-LIST QUERY WITH PROVENANCE TRACKING - MCL 6.0\\n\")\n",
    "cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "flush.console()\n",
    "\n",
    "cat(\"Project:\", PROJECT_NAME, \"\\n\")\n",
    "cat(\"Analysis period:\", START_DATE, \"to\", END_DATE, \"\\n\")\n",
    "cat(\"Number of producer lists:\", length(PRODUCER_LISTS), \"\\n\\n\")\n",
    "flush.console()\n",
    "\n",
    "# STEP 1: Check quota availability\n",
    "# -----------------------------------------------------------------------------\n",
    "cat(\"STEP 1: Checking API quota availability...\\n\")\n",
    "flush.console()\n",
    "\n",
    "if (ENABLE_QUOTA_CHECKS) {\n",
    "  initial_quota <- mcl_check_quota()\n",
    "  \n",
    "  if (initial_quota$over_quota) {\n",
    "    cat(\"ğŸ›‘ CANNOT PROCEED - QUOTA EXCEEDED\\n\")\n",
    "    cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "    cat(\"Your query quota is currently exhausted.\\n\")\n",
    "    cat(\"Please wait for quota reset (7-day rolling window)\\n\")\n",
    "    cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "    flush.console()\n",
    "    stop(\"Analysis cannot proceed - query quota exceeded.\")\n",
    "  }\n",
    "  \n",
    "} else {\n",
    "  cat(\"âš ï¸  QUOTA CHECKS DISABLED - Using assumed quota\\n\")\n",
    "  cat(\"Assumed available quota:\", format(ASSUMED_AVAILABLE_QUOTA, big.mark = \",\"), \"records\\n\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  initial_quota <- list(\n",
    "    available = ASSUMED_AVAILABLE_QUOTA,\n",
    "    total_usage = 0,\n",
    "    max_limit = 500000L,\n",
    "    over_quota = FALSE\n",
    "  )\n",
    "}\n",
    "\n",
    "# STEP 2: Create collection for this research project\n",
    "# -----------------------------------------------------------------------------\n",
    "cat(\"STEP 2: Creating collection for organizing queries...\\n\")\n",
    "flush.console()\n",
    "\n",
    "collection_id <- mcl_create_collection(\n",
    "  name = paste0(PROJECT_NAME, \" - \", Sys.Date()),\n",
    "  description = PROJECT_DESCRIPTION,\n",
    "  set_as_default = TRUE\n",
    ")\n",
    "\n",
    "if (is.null(collection_id)) {\n",
    "  cat(\"âš ï¸  Could not create collection - queries will not be organized\\n\")\n",
    "  flush.console()\n",
    "}\n",
    "\n",
    "# STEP 3: Retrieve all producer lists and build provenance mapping\n",
    "# -----------------------------------------------------------------------------\n",
    "cat(\"STEP 3: Retrieving producer lists and building provenance mapping...\\n\")\n",
    "flush.console()\n",
    "\n",
    "all_producers_with_lists <- data.frame()\n",
    "\n",
    "for (i in seq_along(PRODUCER_LISTS)) {\n",
    "  list_info <- PRODUCER_LISTS[[i]]\n",
    "  list_id <- list_info$list_id\n",
    "  list_name <- list_info$list_name\n",
    "  description <- list_info$description\n",
    "  \n",
    "  cat(\"\\nProcessing list\", i, \"/\", length(PRODUCER_LISTS), \":\\n\")\n",
    "  cat(\"  Name:\", list_name, \"\\n\")\n",
    "  cat(\"  Description:\", description, \"\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  surface_ids <- mcl_get_producer_list(list_name, list_id)\n",
    "  \n",
    "  if (length(surface_ids) > 0) {\n",
    "    list_df <- data.frame(\n",
    "      surface_id = surface_ids,\n",
    "      list_id = list_id,\n",
    "      list_name = list_name,\n",
    "      description = description,\n",
    "      stringsAsFactors = FALSE\n",
    "    )\n",
    "    \n",
    "    all_producers_with_lists <- bind_rows(all_producers_with_lists, list_df)\n",
    "  }\n",
    "}\n",
    "\n",
    "if (nrow(all_producers_with_lists) == 0) {\n",
    "  stop(\"CRITICAL ERROR: No valid producers retrieved from any list.\")\n",
    "}\n",
    "\n",
    "cat(\"\\nğŸ“Š PRODUCER LIST SUMMARY:\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "cat(\"Total producer-list combinations:\", nrow(all_producers_with_lists), \"\\n\")\n",
    "cat(\"Unique producers:\", n_distinct(all_producers_with_lists$surface_id), \"\\n\\n\")\n",
    "flush.console()\n",
    "\n",
    "# STEP 4: Create provenance mapping\n",
    "# -----------------------------------------------------------------------------\n",
    "cat(\"STEP 4: Creating provenance mapping...\\n\")\n",
    "flush.console()\n",
    "\n",
    "producer_provenance <- all_producers_with_lists %>%\n",
    "  group_by(surface_id) %>%\n",
    "  summarise(\n",
    "    n_lists = n(),\n",
    "    list_ids = paste(list_id, collapse = \"; \"),\n",
    "    list_names = paste(list_name, collapse = \"; \"),\n",
    "    .groups = \"drop\"\n",
    "  )\n",
    "\n",
    "# Add boolean columns for each list\n",
    "for (i in seq_along(PRODUCER_LISTS)) {\n",
    "  list_name <- PRODUCER_LISTS[[i]]$list_name\n",
    "  col_name <- paste0(\"in_\", gsub(\"[^[:alnum:]]\", \"_\", list_name))\n",
    "  \n",
    "  producer_provenance[[col_name]] <- sapply(\n",
    "    producer_provenance$surface_id,\n",
    "    function(sid) {\n",
    "      list_name %in% (all_producers_with_lists %>%\n",
    "                        filter(surface_id == sid) %>%\n",
    "                        pull(list_name))\n",
    "    }\n",
    "  )\n",
    "}\n",
    "\n",
    "producer_provenance <- producer_provenance %>%\n",
    "  mutate(\n",
    "    list_overlap = case_when(\n",
    "      n_lists == 1 ~ \"Single list\",\n",
    "      n_lists == 2 ~ \"Two lists\",\n",
    "      n_lists >= 3 ~ \"Three+ lists\",\n",
    "      TRUE ~ \"Unknown\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "cat(\"âœ… Provenance mapping created\\n\\n\")\n",
    "flush.console()\n",
    "\n",
    "cat(\"ğŸ“ˆ PROVENANCE STATISTICS:\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "cat(\"Producers in multiple lists:\", sum(producer_provenance$n_lists > 1), \"\\n\\n\")\n",
    "cat(\"Distribution by number of lists:\\n\")\n",
    "print(table(producer_provenance$n_lists))\n",
    "cat(\"\\n\")\n",
    "flush.console()"
   ],
   "id": "main-workflow-1",
   "cell_type": "code",
   "outputs": []
  },
  {
   "execution_count": null,
   "metadata": {},
   "source": [
    "# STEP 5: Get unique surface IDs for querying\n",
    "# -----------------------------------------------------------------------------\n",
    "cat(\"STEP 5: Preparing unique surface IDs for querying...\\n\")\n",
    "flush.console()\n",
    "\n",
    "unique_surface_ids <- unique(producer_provenance$surface_id)\n",
    "total_unique_producers <- length(unique_surface_ids)\n",
    "\n",
    "cat(\"Unique surface IDs to query:\", total_unique_producers, \"\\n\\n\")\n",
    "flush.console()\n",
    "\n",
    "# STEP 6: Create smart batches\n",
    "# -----------------------------------------------------------------------------\n",
    "cat(\"STEP 6: Creating smart batches based on estimated results...\\n\")\n",
    "flush.console()\n",
    "\n",
    "smart_batches <- mcl_create_smart_batches(\n",
    "  surface_ids = unique_surface_ids,\n",
    "  start_date = START_DATE,\n",
    "  end_date = END_DATE,\n",
    "  max_results = MAX_RESULTS_PER_BATCH\n",
    ")\n",
    "\n",
    "total_estimated_usage <- sum(sapply(smart_batches, function(b) b$estimated_results))\n",
    "total_batched_surfaces <- sum(sapply(smart_batches, function(b) length(b$surface_ids)))\n",
    "\n",
    "cat(\"\\nğŸ“Š BATCH SUMMARY:\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "cat(\"Total batches:\", length(smart_batches), \"\\n\")\n",
    "cat(\"Total estimated results:\", format(total_estimated_usage, big.mark = \",\"), \"\\n\")\n",
    "cat(\"Surfaces batched:\", total_batched_surfaces, \"/\", total_unique_producers, \"\\n\\n\")\n",
    "flush.console()\n",
    "\n",
    "# Check if we have enough quota\n",
    "if (ENABLE_QUOTA_CHECKS && total_estimated_usage > initial_quota$available) {\n",
    "  cat(\"âš ï¸  WARNING: Estimated usage exceeds available quota!\\n\")\n",
    "  cat(\"  Estimated:\", format(total_estimated_usage, big.mark = \",\"), \"\\n\")\n",
    "  cat(\"  Available:\", format(initial_quota$available, big.mark = \",\"), \"\\n\")\n",
    "  cat(\"  Consider reducing date range or number of producers.\\n\\n\")\n",
    "  flush.console()\n",
    "}"
   ],
   "id": "prepare-batches",
   "cell_type": "code",
   "outputs": []
  },
  {
   "execution_count": null,
   "metadata": {},
   "source": [
    "# STEP 7: Execute batch queries\n",
    "# -----------------------------------------------------------------------------\n",
    "cat(\"STEP 7: Executing batch queries...\\n\")\n",
    "cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\")\n",
    "flush.console()\n",
    "\n",
    "all_results <- list()\n",
    "successful_batches <- 0L\n",
    "failed_batches <- 0L\n",
    "actual_quota_used <- 0L\n",
    "\n",
    "for (i in seq_along(smart_batches)) {\n",
    "  batch <- smart_batches[[i]]\n",
    "  \n",
    "  cat(\"\\n\")\n",
    "  cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "  cat(\"BATCH\", i, \"/\", length(smart_batches), \"\\n\")\n",
    "  cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "  cat(\"Surfaces:\", length(batch$surface_ids), \"\\n\")\n",
    "  cat(\"Estimated results:\", format(batch$estimated_results, big.mark = \",\"), \"\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  result <- mcl_execute_async_search(\n",
    "    surface_ids = batch$surface_ids,\n",
    "    start_date = START_DATE,\n",
    "    end_date = END_DATE,\n",
    "    fields = API_FIELDS_STRING,\n",
    "    name = paste0(PROJECT_NAME, \" - Batch \", i, \" of \", length(smart_batches)),\n",
    "    description = paste0(\n",
    "      \"Batch \", i, \": \", length(batch$surface_ids), \" surfaces, \",\n",
    "      \"estimated \", format(batch$estimated_results, big.mark = \",\"), \" results\"\n",
    "    ),\n",
    "    collection_id = collection_id,\n",
    "    output_dir = OUTPUT_DIR\n",
    "  )\n",
    "  \n",
    "  if (!is.null(result$data) && nrow(result$data) > 0) {\n",
    "    all_results[[i]] <- result$data\n",
    "    successful_batches <- successful_batches + 1L\n",
    "    actual_quota_used <- actual_quota_used + nrow(result$data)\n",
    "    cat(\"\\nâœ… Batch\", i, \"completed successfully:\", \n",
    "        format(nrow(result$data), big.mark = \",\"), \"posts\\n\")\n",
    "  } else {\n",
    "    failed_batches <- failed_batches + 1L\n",
    "    cat(\"\\nâŒ Batch\", i, \"failed or returned no data\\n\")\n",
    "  }\n",
    "  flush.console()\n",
    "  \n",
    "  # Rate limiting\n",
    "  if (i < length(smart_batches)) {\n",
    "    cat(\"\\nâ³ Waiting 5 seconds before next batch...\\n\")\n",
    "    flush.console()\n",
    "    Sys.sleep(5)\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"\\n\")\n",
    "cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "cat(\"BATCH EXECUTION COMPLETE\\n\")\n",
    "cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "cat(\"Successful batches:\", successful_batches, \"/\", length(smart_batches), \"\\n\")\n",
    "cat(\"Failed batches:\", failed_batches, \"\\n\")\n",
    "cat(\"Total posts collected:\", format(actual_quota_used, big.mark = \",\"), \"\\n\\n\")\n",
    "flush.console()"
   ],
   "id": "execute-batches",
   "cell_type": "code",
   "outputs": []
  },
  {
   "execution_count": null,
   "metadata": {},
   "source": [
    "# STEP 8: Combine results and add provenance\n",
    "# -----------------------------------------------------------------------------\n",
    "cat(\"STEP 8: Combining results and adding provenance information...\\n\")\n",
    "flush.console()\n",
    "\n",
    "if (length(all_results) > 0) {\n",
    "  all_posts_df <- bind_rows(all_results)\n",
    "  cat(\"Combined\", format(nrow(all_posts_df), big.mark = \",\"), \"posts from all batches\\n\")\n",
    "  flush.console()\n",
    "} else {\n",
    "  cat(\"âŒ No data collected from any batch!\\n\")\n",
    "  flush.console()\n",
    "  stop(\"No data collected - cannot proceed.\")\n",
    "}\n",
    "\n",
    "# Find surface ID column\n",
    "surface_id_col <- NULL\n",
    "possible_cols <- c(\"surface.id\", \"surface_id\", \"surfaceId\")\n",
    "for (col in possible_cols) {\n",
    "  if (col %in% names(all_posts_df)) {\n",
    "    surface_id_col <- col\n",
    "    break\n",
    "  }\n",
    "}\n",
    "\n",
    "if (!is.null(surface_id_col)) {\n",
    "  cat(\"Using surface ID column:\", surface_id_col, \"\\n\")\n",
    "  flush.console()\n",
    "  \n",
    "  posts_with_provenance <- all_posts_df %>%\n",
    "    left_join(\n",
    "      producer_provenance %>% select(surface_id, n_lists, list_names, list_overlap),\n",
    "      by = setNames(\"surface_id\", surface_id_col)\n",
    "    )\n",
    "  \n",
    "  cat(\"âœ… Added provenance information to\", nrow(posts_with_provenance), \"posts\\n\")\n",
    "  flush.console()\n",
    "} else {\n",
    "  posts_with_provenance <- all_posts_df\n",
    "  cat(\"âš ï¸  Could not add provenance - surface ID column not found\\n\")\n",
    "  flush.console()\n",
    "}\n",
    "\n",
    "# STEP 9: Save results\n",
    "# -----------------------------------------------------------------------------\n",
    "cat(\"\\nSTEP 9: Saving results...\\n\")\n",
    "flush.console()\n",
    "\n",
    "# Save as RDS\n",
    "posts_output_path <- file.path(\n",
    "  OUTPUT_DIR,\n",
    "  paste0(\"posts_with_provenance_\", Sys.Date(), \".rds\")\n",
    ")\n",
    "saveRDS(posts_with_provenance, posts_output_path)\n",
    "cat(\"âœ… Saved posts with provenance to:\", posts_output_path, \"\\n\")\n",
    "flush.console()\n",
    "\n",
    "# Save as CSV\n",
    "posts_csv_path <- file.path(\n",
    "  OUTPUT_DIR,\n",
    "  paste0(\"posts_with_provenance_\", Sys.Date(), \".csv\")\n",
    ")\n",
    "write.csv(posts_with_provenance, posts_csv_path, row.names = FALSE)\n",
    "cat(\"âœ… Saved CSV to:\", posts_csv_path, \"\\n\")\n",
    "flush.console()\n",
    "\n",
    "# Save provenance mapping\n",
    "provenance_path <- file.path(\n",
    "  OUTPUT_DIR,\n",
    "  paste0(\"producer_provenance_mapping_\", Sys.Date(), \".csv\")\n",
    ")\n",
    "write.csv(producer_provenance, provenance_path, row.names = FALSE)\n",
    "cat(\"âœ… Saved provenance mapping to:\", provenance_path, \"\\n\")\n",
    "flush.console()"
   ],
   "id": "combine-save",
   "cell_type": "code",
   "outputs": []
  },
  {
   "execution_count": null,
   "metadata": {},
   "source": [
    "# STEP 10: Generate visualizations\n",
    "# -----------------------------------------------------------------------------\n",
    "cat(\"\\nSTEP 10: Generating visualizations...\\n\")\n",
    "flush.console()\n",
    "\n",
    "if (!is.null(surface_id_col) && \"creation_time\" %in% names(posts_with_provenance)) {\n",
    "  ts_by_list <- posts_with_provenance %>%\n",
    "    filter(!is.na(list_names)) %>%\n",
    "    mutate(date = as.Date(creation_time)) %>%\n",
    "    separate_rows(list_names, sep = \"; \") %>%\n",
    "    group_by(date, list_names) %>%\n",
    "    summarise(\n",
    "      n_posts = n(),\n",
    "      .groups = \"drop\"\n",
    "    )\n",
    "  \n",
    "  if (nrow(ts_by_list) > 0) {\n",
    "    p1 <- ggplot(ts_by_list, aes(x = date, y = n_posts, color = list_names)) +\n",
    "      geom_line(linewidth = 1) +\n",
    "      theme_minimal(base_size = 12) +\n",
    "      labs(\n",
    "        title = \"Posts Over Time by Producer List\",\n",
    "        subtitle = paste(\"Data from\", START_DATE, \"to\", END_DATE),\n",
    "        x = \"Date\",\n",
    "        y = \"Number of Posts\",\n",
    "        color = \"Producer List\"\n",
    "      ) +\n",
    "      theme(\n",
    "        legend.position = \"bottom\",\n",
    "        plot.title = element_text(face = \"bold\", size = 14)\n",
    "      )\n",
    "    \n",
    "    plot1_path <- file.path(OUTPUT_DIR, \"posts_by_list_over_time.png\")\n",
    "    ggsave(plot1_path, plot = p1, width = 12, height = 6, dpi = 300, bg = \"white\")\n",
    "    cat(\"âœ… Saved plot to:\", plot1_path, \"\\n\")\n",
    "    flush.console()\n",
    "  }\n",
    "}\n",
    "\n",
    "# STEP 11: Final summary\n",
    "# -----------------------------------------------------------------------------\n",
    "cat(\"\\n\")\n",
    "cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "cat(\"ANALYSIS SUMMARY\\n\")\n",
    "cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\")\n",
    "flush.console()\n",
    "\n",
    "cat(\"ğŸ“Š DATA COLLECTION METRICS:\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "cat(\"  Producer Lists Queried:\", length(PRODUCER_LISTS), \"\\n\")\n",
    "cat(\"  Unique Producers:\", total_unique_producers, \"\\n\")\n",
    "cat(\"  Surfaces Batched:\", total_batched_surfaces, \"/\", total_unique_producers, \"\\n\")\n",
    "cat(\"  Posts Collected:\", format(nrow(posts_with_provenance), big.mark = \",\"), \"\\n\")\n",
    "cat(\"  Quota Used:\", format(actual_quota_used, big.mark = \",\"), \"/\",\n",
    "    format(total_estimated_usage, big.mark = \",\"), \"estimated\\n\")\n",
    "cat(\"  Collection ID:\", ifelse(is.null(collection_id), \"None\", collection_id), \"\\n\\n\")\n",
    "flush.console()\n",
    "\n",
    "cat(\"ğŸ”§ BATCHING METRICS:\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "cat(\"  Total batches:\", length(smart_batches), \"\\n\")\n",
    "cat(\"  Successful:\", successful_batches, \"\\n\")\n",
    "cat(\"  Failed:\", failed_batches, \"\\n\")\n",
    "cat(\"  Success rate:\", round(100 * successful_batches / length(smart_batches), 1), \"%\\n\\n\")\n",
    "flush.console()\n",
    "\n",
    "# Check final quota\n",
    "if (ENABLE_QUOTA_CHECKS) {\n",
    "  cat(\"ğŸ“Š FINAL QUOTA STATUS:\\n\")\n",
    "  cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "  flush.console()\n",
    "  final_quota <- mcl_check_quota()\n",
    "}\n",
    "\n",
    "cat(\"\\nğŸ“ OUTPUT FILES:\\n\")\n",
    "cat(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\")\n",
    "cat(\"  â€¢\", posts_output_path, \"\\n\")\n",
    "cat(\"  â€¢\", posts_csv_path, \"\\n\")\n",
    "cat(\"  â€¢\", provenance_path, \"\\n\")\n",
    "if (exists(\"plot1_path\")) {\n",
    "  cat(\"  â€¢\", plot1_path, \"\\n\")\n",
    "}\n",
    "cat(\"\\n\")\n",
    "flush.console()\n",
    "\n",
    "cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "cat(\"âœ… ANALYSIS COMPLETED SUCCESSFULLY\\n\")\n",
    "cat(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
    "cat(\"\\nâš ï¸  REMINDER: Export entire notebook to save results!\\n\\n\")\n",
    "flush.console()"
   ],
   "id": "final-summary",
   "cell_type": "code",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4
}