{
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat_minor": 5,
 "cells": [
  {
   "metadata": {},
   "execution_count": null,
   "source": "# =============================================================================\n# SURFACE INFO ENRICHMENT SCRIPT v5.0 (FIXED RESPONSE PARSING)\n# Meta Political Content Research - Italian Parliamentarians Dataset\n# =============================================================================\n#\n# FIX: Corrected response parsing logic. The API returns data in $data field\n#      as a data frame, but previous version wasn't detecting it correctly.\n#\n# =============================================================================\n\nlibrary(reticulate)\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Load shared utilities and configuration\nsource(\"scripts/utils.R\")\nconfig <- load_config(\"IT\")\n\ncat(\"\\n\")\ncat(\"═══════════════════════════════════════════════════════════════════════\\n\")\ncat(\"     SURFACE INFO ENRICHMENT SCRIPT v5.0\\n\")\ncat(\"     (Fixed Response Parsing)\\n\")\ncat(\"═══════════════════════════════════════════════════════════════════════\\n\\n\")\nflush.console()\n\n# =============================================================================\n# CONFIGURATION\n# =============================================================================\n\ndata_dir <- config$paths$cleaned_data\n# API operational parameters (not in config as they're implementation-specific)\nbatch_size <- 25L\npause_between_batches <- 2L\n\n# =============================================================================\n# STEP 1: LOAD INPUT FILES\n# =============================================================================\n\ncat(\"STEP 1: Loading input files...\\n\")\ncat(\"─────────────────────────────────────────────────────────────────────\\n\\n\")\nflush.console()\n\nsurface_id_file <- find_most_recent_file(data_dir, \"surface_ids_for_api_.*\\\\.csv$\")\nif (is.null(surface_id_file)) {\n  stop(\"No surface_ids_for_api_*.csv found in \", data_dir)\n}\n\ncat(\"Using:\", basename(surface_id_file), \"\\n\")\nflush.console()\n\nsurface_ids_df <- read.csv(surface_id_file, stringsAsFactors = FALSE)\ncat(\"  Loaded\", nrow(surface_ids_df), \"surface IDs\\n\\n\")\nflush.console()\n\n# Load surface_info if available\nsurface_info_file <- find_most_recent_file(data_dir, \"surface_info_.*\\\\.rds$\")\nif (!is.null(surface_info_file)) {\n  cat(\"Found surface_info:\", basename(surface_info_file), \"\\n\")\n  surface_info <- readRDS(surface_info_file)\n  cat(\"  Loaded\", nrow(surface_info), \"records\\n\\n\")\n  flush.console()\n} else {\n  surface_info <- NULL\n}\n\ntarget_ids <- unique(as.character(surface_ids_df$surface.id))\ncat(\"Total unique IDs:\", length(target_ids), \"\\n\\n\")\nflush.console()\n\n# =============================================================================\n# STEP 2: INITIALIZE API CLIENT\n# =============================================================================\n\ncat(\"STEP 2: Initializing API client...\\n\")\ncat(\"─────────────────────────────────────────────────────────────────────\\n\\n\")\nflush.console()\n\nclient <- import(\"metacontentlibraryapi\")$MetaContentLibraryAPIClient\nclient$set_default_version(client$LATEST_VERSION)\ncat(\"✓ API client initialized\\n\\n\")\nflush.console()\n\n# =============================================================================\n# STEP 3: CHECK QUOTA\n# =============================================================================\n\ncat(\"STEP 3: Checking quota...\\n\")\ncat(\"─────────────────────────────────────────────────────────────────────\\n\\n\")\nflush.console()\n\ntryCatch({\n  response <- client$get(path = \"budgets\")\n  budgets <- fromJSON(response$text, flatten = TRUE)\n  cat(sprintf(\"  Available: %s records\\n\\n\", \n              format(budgets$queries$max_usage_limit - budgets$queries$total_usage, big.mark = \",\")))\n  flush.console()\n}, error = function(e) {\n  cat(\"⚠ Could not check quota\\n\\n\")\n  flush.console()\n})\n\n# =============================================================================\n# HELPER FUNCTIONS (FIXED)\n# =============================================================================\n\n#' Query entities - FIXED response parsing\n#' @param ids Vector of IDs\n#' @param entity_type One of: \"page\", \"group\", \"profile\", \"event\"\n#' @return List with success status and data\nquery_entities <- function(ids, entity_type) {\n  \n  config <- list(\n    page = list(path = \"facebook/pages/preview\", param = \"page_ids\"),\n    group = list(path = \"facebook/groups/preview\", param = \"group_ids\"),\n    profile = list(path = \"facebook/profiles/preview\", param = \"profile_ids\"),\n    event = list(path = \"facebook/events/preview\", param = \"event_ids\")\n  )[[entity_type]]\n  \n  if (is.null(config)) {\n    return(list(success = FALSE, data = NULL, error = \"Unknown entity type\"))\n  }\n  \n  params <- list()\n  params[[config$param]] <- as.list(as.character(ids))\n  \n  tryCatch({\n    response <- client$get(path = config$path, params = params)\n    result <- fromJSON(response$text, flatten = TRUE)\n    \n    # FIXED: Properly check for data in response\n    # The API returns: list with $data element containing data frame\n    \n    data_df <- NULL\n    \n    # Check $data field (most common structure)\n    if (!is.null(result$data)) {\n      if (is.data.frame(result$data)) {\n        data_df <- result$data\n      } else if (is.list(result$data) && length(result$data) > 0) {\n        # Try to convert list to data frame\n        data_df <- tryCatch(\n          bind_rows(result$data),\n          error = function(e) as.data.frame(result$data, stringsAsFactors = FALSE)\n        )\n      }\n    }\n    \n    # Check if result itself is a data frame\n    if (is.null(data_df) && is.data.frame(result) && nrow(result) > 0) {\n      data_df <- result\n    }\n    \n    # Return results\n    if (!is.null(data_df) && is.data.frame(data_df) && nrow(data_df) > 0) {\n      data_df$entity_type <- toupper(entity_type)\n      return(list(success = TRUE, data = data_df, error = NULL))\n    } else {\n      return(list(success = TRUE, data = NULL, error = NULL))  # No error, just no data\n    }\n    \n  }, error = function(e) {\n    return(list(success = FALSE, data = NULL, error = e$message))\n  })\n}\n\n#' Query single ID across all entity types\ndetect_entity_type <- function(id) {\n  for (etype in c(\"page\", \"group\", \"profile\", \"event\")) {\n    result <- query_entities(id, etype)\n    \n    if (result$success && !is.null(result$data) && nrow(result$data) > 0) {\n      return(list(found = TRUE, entity_type = toupper(etype), data = result$data))\n    }\n    \n    # Small delay between API calls\n    Sys.sleep(0.2)\n  }\n  \n  return(list(found = FALSE, entity_type = \"UNKNOWN\", data = NULL))\n}\n\n# =============================================================================\n# STEP 4: QUERY ALL IDS AS PAGES FIRST\n# =============================================================================\n\ncat(\"STEP 4: Querying as Facebook Pages...\\n\")\ncat(\"─────────────────────────────────────────────────────────────────────\\n\\n\")\nflush.console()\n\nbatches <- split(target_ids, ceiling(seq_along(target_ids) / batch_size))\ntotal_batches <- length(batches)\n\ncat(\"Total IDs:\", length(target_ids), \"\\n\")\ncat(\"Batches:\", total_batches, \"\\n\\n\")\nflush.console()\n\nall_page_data <- list()\nids_not_found_as_pages <- character(0)\n\nfor (i in seq_along(batches)) {\n  batch_ids <- batches[[i]]\n  \n  cat(\"Batch\", i, \"/\", total_batches, \"...\")\n  flush.console()\n  \n  result <- query_entities(batch_ids, \"page\")\n  \n  if (!result$success) {\n    # API error - try individually\n    cat(\" error, retrying individually\\n\")\n    flush.console()\n    \n    for (id in batch_ids) {\n      single_result <- query_entities(id, \"page\")\n      if (single_result$success && !is.null(single_result$data) && nrow(single_result$data) > 0) {\n        all_page_data[[length(all_page_data) + 1]] <- single_result$data\n      } else {\n        ids_not_found_as_pages <- c(ids_not_found_as_pages, id)\n      }\n      Sys.sleep(0.3)\n    }\n    \n  } else if (!is.null(result$data) && nrow(result$data) > 0) {\n    # Success - check which IDs were returned\n    cat(\" ✓\", nrow(result$data), \"found\\n\")\n    flush.console()\n    \n    all_page_data[[length(all_page_data) + 1]] <- result$data\n    \n    # Track IDs not in response\n    returned_ids <- as.character(result$data$id)\n    missing <- setdiff(batch_ids, returned_ids)\n    if (length(missing) > 0) {\n      ids_not_found_as_pages <- c(ids_not_found_as_pages, missing)\n    }\n    \n  } else {\n    # No data returned - all IDs in batch need checking\n    cat(\" no data\\n\")\n    flush.console()\n    ids_not_found_as_pages <- c(ids_not_found_as_pages, batch_ids)\n  }\n  \n  if (i < total_batches) Sys.sleep(pause_between_batches)\n  \n  # Longer pause every 30 batches\n  if (i %% 30 == 0 && i < total_batches) {\n    cat(\"\\n⏳ Pausing 15 seconds...\\n\\n\")\n    flush.console()\n    Sys.sleep(15)\n  }\n}\n\n# Combine page data\npage_data <- if (length(all_page_data) > 0) {\n  tryCatch(bind_rows(all_page_data), error = function(e) {\n    cat(\"Note: Manual combination needed\\n\")\n    flush.console()\n    do.call(rbind, lapply(all_page_data, function(df) {\n      df[, intersect(names(df), names(all_page_data[[1]]))]\n    }))\n  })\n} else {\n  data.frame()\n}\n\nids_not_found_as_pages <- unique(ids_not_found_as_pages)\n\ncat(\"\\n─────────────────────────────────────────────────────────────────────\\n\")\ncat(\"Pages query complete:\\n\")\ncat(\"  Found as Pages:\", nrow(page_data), \"\\n\")\ncat(\"  Need further checking:\", length(ids_not_found_as_pages), \"\\n\")\ncat(\"─────────────────────────────────────────────────────────────────────\\n\\n\")\nflush.console()\n\n# =============================================================================\n# STEP 5: CHECK NON-PAGE IDS FOR OTHER ENTITY TYPES\n# =============================================================================\n\ngroup_data <- data.frame()\nprofile_data <- data.frame()\nevent_data <- data.frame()\ntruly_invalid_ids <- character(0)\nentity_type_log <- data.frame()\n\nif (length(ids_not_found_as_pages) > 0) {\n  \n  cat(\"STEP 5: Checking\", length(ids_not_found_as_pages), \"IDs for Groups/Profiles/Events...\\n\")\n  cat(\"─────────────────────────────────────────────────────────────────────\\n\\n\")\n  flush.console()\n  \n  group_list <- list()\n  profile_list <- list()\n  event_list <- list()\n  \n  for (i in seq_along(ids_not_found_as_pages)) {\n    id <- ids_not_found_as_pages[i]\n    \n    # Progress\n    if (i %% 25 == 1 || i == length(ids_not_found_as_pages)) {\n      cat(sprintf(\"Checking %d/%d (%.0f%%)...\\n\", \n                  i, length(ids_not_found_as_pages), \n                  (i/length(ids_not_found_as_pages))*100))\n      flush.console()\n    }\n    \n    found <- FALSE\n    \n    # Try GROUP\n    result <- query_entities(id, \"group\")\n    if (result$success && !is.null(result$data) && nrow(result$data) > 0) {\n      group_list[[length(group_list) + 1]] <- result$data\n      entity_type_log <- rbind(entity_type_log, data.frame(\n        surface_id = id, entity_type = \"GROUP\",\n        name = if (\"name\" %in% names(result$data)) result$data$name[1] else NA,\n        stringsAsFactors = FALSE))\n      cat(\"  ✓ GROUP:\", id, \"\\n\")\n      flush.console()\n      found <- TRUE\n    }\n    Sys.sleep(0.2)\n    \n    # Try PROFILE\n    if (!found) {\n      result <- query_entities(id, \"profile\")\n      if (result$success && !is.null(result$data) && nrow(result$data) > 0) {\n        profile_list[[length(profile_list) + 1]] <- result$data\n        entity_type_log <- rbind(entity_type_log, data.frame(\n          surface_id = id, entity_type = \"PROFILE\",\n          name = if (\"name\" %in% names(result$data)) result$data$name[1] else NA,\n          stringsAsFactors = FALSE))\n        cat(\"  ✓ PROFILE:\", id, \"\\n\")\n        flush.console()\n        found <- TRUE\n      }\n      Sys.sleep(0.2)\n    }\n    \n    # Try EVENT\n    if (!found) {\n      result <- query_entities(id, \"event\")\n      if (result$success && !is.null(result$data) && nrow(result$data) > 0) {\n        event_list[[length(event_list) + 1]] <- result$data\n        entity_type_log <- rbind(entity_type_log, data.frame(\n          surface_id = id, entity_type = \"EVENT\",\n          name = if (\"name\" %in% names(result$data)) result$data$name[1] else NA,\n          stringsAsFactors = FALSE))\n        cat(\"  ✓ EVENT:\", id, \"\\n\")\n        flush.console()\n        found <- TRUE\n      }\n      Sys.sleep(0.2)\n    }\n    \n    # Not found anywhere - DOUBLE CHECK as page individually\n    if (!found) {\n      # One more try as page (in case batch missed it)\n      result <- query_entities(id, \"page\")\n      if (result$success && !is.null(result$data) && nrow(result$data) > 0) {\n        all_page_data[[length(all_page_data) + 1]] <- result$data\n        entity_type_log <- rbind(entity_type_log, data.frame(\n          surface_id = id, entity_type = \"PAGE\",\n          name = if (\"name\" %in% names(result$data)) result$data$name[1] else NA,\n          stringsAsFactors = FALSE))\n        cat(\"  ✓ PAGE (retry):\", id, \"\\n\")\n        flush.console()\n        found <- TRUE\n      }\n      Sys.sleep(0.2)\n    }\n    \n    if (!found) {\n      truly_invalid_ids <- c(truly_invalid_ids, id)\n      entity_type_log <- rbind(entity_type_log, data.frame(\n        surface_id = id, entity_type = \"UNKNOWN\", name = NA, stringsAsFactors = FALSE))\n    }\n    \n    # Rate limiting pause\n    if (i %% 50 == 0 && i < length(ids_not_found_as_pages)) {\n      cat(\"\\n⏳ Pausing 10 seconds...\\n\\n\")\n      flush.console()\n      Sys.sleep(10)\n    }\n  }\n  \n  # Combine by type\n  if (length(group_list) > 0) group_data <- tryCatch(bind_rows(group_list), error = function(e) data.frame())\n  if (length(profile_list) > 0) profile_data <- tryCatch(bind_rows(profile_list), error = function(e) data.frame())\n  if (length(event_list) > 0) event_data <- tryCatch(bind_rows(event_list), error = function(e) data.frame())\n  \n  # Update page_data with retry successes\n  if (length(all_page_data) > length(page_data)) {\n    page_data <- tryCatch(bind_rows(all_page_data), error = function(e) page_data)\n  }\n  \n  cat(\"\\n─────────────────────────────────────────────────────────────────────\\n\")\n  cat(\"Entity detection complete:\\n\")\n  cat(\"  Groups:\", nrow(group_data), \"\\n\")\n  cat(\"  Profiles:\", nrow(profile_data), \"\\n\")\n  cat(\"  Events:\", nrow(event_data), \"\\n\")\n  cat(\"  Truly invalid:\", length(truly_invalid_ids), \"\\n\")\n  cat(\"─────────────────────────────────────────────────────────────────────\\n\\n\")\n  flush.console()\n  \n} else {\n  cat(\"STEP 5: Skipped - all IDs found as Pages\\n\\n\")\n  flush.console()\n}\n\n# =============================================================================\n# STEP 6: COMBINE ALL DATA\n# =============================================================================\n\ncat(\"STEP 6: Combining all data...\\n\")\ncat(\"─────────────────────────────────────────────────────────────────────\\n\\n\")\nflush.console()\n\n# Ensure entity_type column exists\nif (nrow(page_data) > 0 && !\"entity_type\" %in% names(page_data)) page_data$entity_type <- \"PAGE\"\nif (nrow(group_data) > 0 && !\"entity_type\" %in% names(group_data)) group_data$entity_type <- \"GROUP\"\nif (nrow(profile_data) > 0 && !\"entity_type\" %in% names(profile_data)) profile_data$entity_type <- \"PROFILE\"\nif (nrow(event_data) > 0 && !\"entity_type\" %in% names(event_data)) event_data$entity_type <- \"EVENT\"\n\n# Add surface.id from id\nadd_surface_id <- function(df) {\n  if (nrow(df) > 0 && \"id\" %in% names(df)) {\n    df$surface.id <- as.character(df$id)\n  }\n  df\n}\n\npage_data <- add_surface_id(page_data)\ngroup_data <- add_surface_id(group_data)\nprofile_data <- add_surface_id(profile_data)\nevent_data <- add_surface_id(event_data)\n\n# Combine all\nall_api_data <- tryCatch({\n  bind_rows(page_data, group_data, profile_data, event_data)\n}, error = function(e) {\n  cat(\"Manual combination needed\\n\")\n  flush.console()\n  \n  # Find common columns\n  all_dfs <- list(page_data, group_data, profile_data, event_data)\n  all_dfs <- all_dfs[sapply(all_dfs, function(x) nrow(x) > 0)]\n  \n  if (length(all_dfs) == 0) return(data.frame())\n  \n  common_cols <- Reduce(intersect, lapply(all_dfs, names))\n  do.call(rbind, lapply(all_dfs, function(df) df[, common_cols, drop = FALSE]))\n})\n\ncat(\"Total API records:\", nrow(all_api_data), \"\\n\\n\")\nflush.console()\n\nif (nrow(all_api_data) > 0) {\n  cat(\"Entity type breakdown:\\n\")\n  print(table(all_api_data$entity_type))\n  cat(\"\\n\")\n  flush.console()\n}\n\n# =============================================================================\n# STEP 7: PREPARE FOR MERGE\n# =============================================================================\n\ncat(\"STEP 7: Preparing for merge...\\n\")\ncat(\"─────────────────────────────────────────────────────────────────────\\n\\n\")\nflush.console()\n\nif (nrow(all_api_data) > 0) {\n  # Add api_ prefix to columns (except surface.id, entity_type)\n  keep_cols <- c(\"surface.id\", \"entity_type\")\n  rename_cols <- setdiff(names(all_api_data), keep_cols)\n  \n  for (col in rename_cols) {\n    names(all_api_data)[names(all_api_data) == col] <- paste0(\"api_\", col)\n  }\n  \n  cat(\"Columns prepared:\", ncol(all_api_data), \"\\n\\n\")\n  flush.console()\n}\n\n# =============================================================================\n# STEP 8: MERGE WITH SURFACE INFO\n# =============================================================================\n\ncat(\"STEP 8: Merging with surface_info...\\n\")\ncat(\"─────────────────────────────────────────────────────────────────────\\n\\n\")\nflush.console()\n\nif (nrow(all_api_data) > 0) {\n  if (!is.null(surface_info)) {\n    surface_info$surface.id <- as.character(surface_info$surface.id)\n    all_api_data$surface.id <- as.character(all_api_data$surface.id)\n    \n    surface_info_enriched <- surface_info %>%\n      left_join(all_api_data, by = \"surface.id\")\n    \n    cat(\"✓ Merged successfully\\n\")\n    cat(\"  Rows:\", nrow(surface_info_enriched), \"\\n\")\n    cat(\"  Columns:\", ncol(surface_info_enriched), \"\\n\\n\")\n    flush.console()\n  } else {\n    surface_ids_df$surface.id <- as.character(surface_ids_df$surface.id)\n    surface_info_enriched <- surface_ids_df %>%\n      left_join(all_api_data, by = \"surface.id\")\n    cat(\"✓ Created enriched dataset\\n\\n\")\n    flush.console()\n  }\n} else {\n  surface_info_enriched <- surface_info\n  cat(\"⚠ No API data to merge\\n\\n\")\n  flush.console()\n}\n\n# =============================================================================\n# STEP 9: SAVE OUTPUTS\n# =============================================================================\n\ncat(\"STEP 9: Saving outputs...\\n\")\ncat(\"─────────────────────────────────────────────────────────────────────\\n\\n\")\nflush.console()\n\ntimestamp <- format(Sys.time(), \"%Y%m%d_%H%M%S\")\n\n# Helper to safely save CSV (convert lists to JSON)\nsafe_write_csv <- function(df, filepath) {\n  df_copy <- df\n  for (col in names(df_copy)) {\n    if (is.list(df_copy[[col]])) {\n      df_copy[[col]] <- sapply(df_copy[[col]], function(x) {\n        if (is.null(x) || length(x) == 0) NA_character_\n        else tryCatch(as.character(toJSON(x, auto_unbox = TRUE)), \n                      error = function(e) paste(x, collapse = \"; \"))\n      })\n    }\n  }\n  write.csv(df_copy, filepath, row.names = FALSE, fileEncoding = \"UTF-8\")\n}\n\n# Save enriched data\nif (!is.null(surface_info_enriched)) {\n  rds_file <- file.path(data_dir, paste0(\"surface_info_enriched_\", timestamp, \".rds\"))\n  saveRDS(surface_info_enriched, rds_file)\n  cat(\"✓ RDS:\", basename(rds_file), \"\\n\")\n  flush.console()\n  \n  csv_file <- file.path(data_dir, paste0(\"surface_info_enriched_\", timestamp, \".csv\"))\n  tryCatch({\n    safe_write_csv(surface_info_enriched, csv_file)\n    cat(\"✓ CSV:\", basename(csv_file), \"\\n\")\n    flush.console()\n  }, error = function(e) {\n    cat(\"⚠ CSV failed:\", e$message, \"\\n\")\n    flush.console()\n  })\n}\n\n# Save entity type log\nif (nrow(entity_type_log) > 0) {\n  log_file <- file.path(data_dir, paste0(\"entity_type_log_\", timestamp, \".csv\"))\n  write.csv(entity_type_log, log_file, row.names = FALSE)\n  cat(\"✓ Entity log:\", basename(log_file), \"\\n\")\n  flush.console()\n}\n\n# Save truly invalid IDs\nif (length(truly_invalid_ids) > 0) {\n  invalid_file <- file.path(data_dir, paste0(\"truly_invalid_ids_\", timestamp, \".csv\"))\n  write.csv(data.frame(surface_id = truly_invalid_ids), invalid_file, row.names = FALSE)\n  cat(\"✓ Invalid IDs:\", basename(invalid_file), \"\\n\")\n  flush.console()\n}\n\n# =============================================================================\n# SUMMARY\n# =============================================================================\n\ncat(\"\\n\")\ncat(\"═══════════════════════════════════════════════════════════════════════\\n\")\ncat(\"                           SUMMARY\\n\")\ncat(\"═══════════════════════════════════════════════════════════════════════\\n\\n\")\nflush.console()\n\ncat(\"Input: \", length(target_ids), \" IDs\\n\\n\", sep = \"\")\n\ncat(\"Results by Entity Type:\\n\")\ncat(\"  Pages:    \", nrow(page_data), \"\\n\", sep = \"\")\ncat(\"  Groups:   \", nrow(group_data), \"\\n\", sep = \"\")\ncat(\"  Profiles: \", nrow(profile_data), \"\\n\", sep = \"\")\ncat(\"  Events:   \", nrow(event_data), \"\\n\", sep = \"\")\ncat(\"  Invalid:  \", length(truly_invalid_ids), \"\\n\\n\", sep = \"\")\n\ntotal_found <- nrow(page_data) + nrow(group_data) + nrow(profile_data) + nrow(event_data)\ncat(\"Total found: \", total_found, \" / \", length(target_ids), \n    \" (\", sprintf(\"%.1f\", (total_found/length(target_ids))*100), \"%)\\n\\n\", sep = \"\")\n\ncat(\"═══════════════════════════════════════════════════════════════════════\\n\")\ncat(\"                        COMPLETE\\n\")\ncat(\"═══════════════════════════════════════════════════════════════════════\\n\\n\")\nflush.console()\n\ncat(\"Load enriched data with:\\n\")\ncat(\"  data <- readRDS('\", rds_file, \"')\\n\\n\", sep = \"\")\nflush.console()",
   "id": "9abb35b4-9f94-466c-9fa1-14dcd15aaf21",
   "cell_type": "code",
   "outputs": []
  }
 ],
 "nbformat": 4
}