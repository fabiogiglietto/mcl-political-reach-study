{"metadata": {"kernelspec": {"display_name": "R", "language": "R", "name": "ir"}, "language_info": {"codemirror_mode": "r", "file_extension": ".r", "mimetype": "text/x-r-source", "name": "R", "pygments_lexer": "r", "version": "4.3.3"}}, "nbformat_minor": 5, "cells": [{"metadata": {}, "execution_count": 1, "source": ["# ============================================================================\n", "# RQ1: WHEN AND TO WHAT EXTENT DOES META'S POLICY AFFECT REACH?\n", "# Data-Driven Breakpoint Analysis (Cross-Algorithm Validated)\n", "# VERSION 4: Updated Table/Figure Numbering to Match Working Paper\n", "# ============================================================================\n", "# \n", "# RESEARCH DESIGN:\n", "# ----------------\n", "# RQ1: When and to what extent did Meta's political content reduction policy\u2014\n", "#      and its subsequent reversal\u2014affect political actors' reach on Facebook \n", "#      in Italy?\n", "#\n", "# METHODOLOGY: Cross-Algorithm Validated Breakpoint Detection\n", "# -----------------------------------------------------------\n", "# This analysis uses a SINGLE, CONSISTENT breakpoint identification approach:\n", "#\n", "#   STEP 1 - DETECTION:\n", "#     \u2022 Run Bai-Perron structural break detection on 4 metrics (views, reactions,\n", "#       shares, comments)\n", "#     \u2022 Run PELT changepoint detection on the same 4 metrics\n", "#     \u2022 Total: Up to 8 possible detections per method cluster\n", "#\n", "#   STEP 2 - CLUSTERING:\n", "#     \u2022 Group detected dates within a 30-day tolerance window\n", "#     \u2022 Calculate consensus date (median) and detection spread (range)\n", "#\n", "#   STEP 3 - CROSS-VALIDATION:\n", "#     \u2022 Retain only breakpoints detected by BOTH algorithms (Bai-Perron AND PELT)\n", "#     \u2022 This ensures statistical robustness across methodologies\n", "#\n", "#   STEP 4 - FINAL SELECTION (Three-Breakpoint Model):\n", "#     When \u22653 cross-validated breakpoints exist:\n", "#       \u2022 T1: First chronological breakpoint (Policy Implementation)\n", "#       \u2022 T3: First breakpoint after Sept 2024 OR last chronological (Reversal)\n", "#       \u2022 T2: Among remaining intermediate breakpoints, select the one with\n", "#             MOST method detections (strongest evidence); ties broken by date\n", "#     When 2 breakpoints: T1 + T3 only (no T2)\n", "#     When 1 breakpoint: T1 only\n", "#\n", "# WORKING PAPER TABLE/FIGURE MAPPING:\n", "# -----------------------------------\n", "# Table 1:  Political Actor Groups (descriptive - not generated here)\n", "# Table 2:  Account and Post Counts by Group\n", "# Table 3:  Weekly Aggregated Engagement Statistics\n", "# Table 4:  Cross-Validated Breakpoints\n", "# Table 5:  Reach Statistics by Policy Phase (Re-elected MPs)\n", "# Table 6:  Engagement Metrics by Policy Phase (Re-elected MPs)\n", "# Table 7:  Breakpoint Validation Across Groups\n", "# Table 8:  Cross-Group Magnitude Comparison (Views)\n", "# Table 9:  Pairwise Phase Comparisons (Dunn's Test)\n", "# Table 10: Per-Post vs Total Weekly Reach by Group\n", "#\n", "# Figure 1: Time series of all groups with breakpoints\n", "# Figure 2: MPs Reelected trends with breakpoints\n", "# Figure 3: Individual group trends (faceted validation)\n", "#\n", "# Discovery Sample: Re-elected MPs (continuous presence 2020-2025)\n", "# Validation Groups: New MPs, Prominent Politicians, Extremists\n", "#\n", "# Dataset: weekly_aggregation (as per DATASETS_QUICK_REFERENCE.md)\n", "# ============================================================================\n", "\n", "# Required packages\n", "required_packages <- c(\n", "  \"tidyverse\", \"lubridate\", \"strucchange\", \"changepoint\", \n", "  \"zoo\", \"segmented\", \"patchwork\", \"scales\", \"knitr\", \"moments\"\n", ")\n", "\n", "for (pkg in required_packages) {\n", "  if (!require(pkg, character.only = TRUE, quietly = TRUE)) {\n", "    install.packages(pkg, dependencies = TRUE)\n", "  }\n", "  library(pkg, character.only = TRUE)\n", "}\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"RQ1 ANALYSIS: META'S POLITICAL CONTENT POLICY EFFECTS IN ITALY\\n\")\n", "cat(\"Cross-Algorithm Validated Breakpoint Detection\\n\")\n", "cat(\"Version 4: Table/Figure Numbering Aligned with Working Paper\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "# ============================================================================\n", "# STEP 1: LOAD DATA\n", "# ============================================================================\n", "\n", "cat(\"STEP 1: LOADING DATA\\n\")\n", "cat(rep(\"-\", 40), \"\\n\\n\", sep = \"\")\n", "\n", "# Find the most recent weekly aggregation file\n", "weekly_files <- list.files(\n", "  path = \"cleaned_data\",\n", "  pattern = \"weekly_aggregation_.*\\\\.rds$\",\n", "  full.names = TRUE\n", ")\n", "\n", "if (length(weekly_files) == 0) {\n", "  stop(\"No weekly_aggregation files found in cleaned_data/\")\n", "}\n", "\n", "weekly_file <- sort(weekly_files, decreasing = TRUE)[1]\n", "cat(\"Loading weekly data:\", weekly_file, \"\\n\")\n", "weekly_data <- readRDS(weekly_file)\n", "\n", "cat(\"\\nData structure:\\n\")\n", "cat(\"  Rows:\", nrow(weekly_data), \"\\n\")\n", "cat(\"  Columns:\", ncol(weekly_data), \"\\n\")\n", "cat(\"  Date range:\", as.character(min(weekly_data$week)), \"to\", \n", "    as.character(max(weekly_data$week)), \"\\n\\n\")\n", "\n", "# Detect dataset version (3-group vs 4-group)\n", "mp_groups <- unique(weekly_data$main_list[grepl(\"^MPs\", weekly_data$main_list)])\n", "all_groups <- unique(weekly_data$main_list)\n", "\n", "dataset_version <- if (length(mp_groups) > 1) \"v3.2_split\" else \"v2_v3.1\"\n", "\n", "# Identify discovery and validation samples\n", "discovery_group <- if (\"MPs_Reelected\" %in% all_groups) \"MPs_Reelected\" else \"MPs\"\n", "validation_groups <- setdiff(all_groups, discovery_group)\n", "\n", "cat(\"Dataset Configuration:\\n\")\n", "cat(\"  Version:\", dataset_version, \"\\n\")\n", "cat(\"  Discovery sample:\", discovery_group, \"\\n\")\n", "cat(\"  Validation groups:\", paste(validation_groups, collapse = \", \"), \"\\n\\n\")\n", "\n", "# ============================================================================\n", "# TABLE 2: ACCOUNT AND POST COUNTS BY GROUP\n", "# (Working Paper Table 2)\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"TABLE 2: ACCOUNT AND POST COUNTS BY GROUP\\n\")\n", "cat(\"(Working Paper Table 2)\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "# Load accounts summary for n_accounts if available\n", "accounts_files <- list.files(\n", "  path = \"cleaned_data\",\n", "  pattern = \"accounts_summary_.*\\\\.rds$\",\n", "  full.names = TRUE\n", ")\n", "\n", "# Calculate Table 2 statistics from weekly data\n", "table2_from_weekly <- weekly_data %>%\n", "  group_by(main_list) %>%\n", "  summarise(\n", "    n_weeks = n(),\n", "    total_posts = sum(n_posts, na.rm = TRUE),\n", "    total_views = sum(total_views, na.rm = TRUE),\n", "    avg_views_overall = mean(avg_views, na.rm = TRUE),\n", "    .groups = \"drop\"\n", "  )\n", "\n", "# Try to get account counts from accounts_summary\n", "if (length(accounts_files) > 0) {\n", "  accounts_summary <- readRDS(sort(accounts_files, decreasing = TRUE)[1])\n", "  \n", "  account_counts <- accounts_summary %>%\n", "    group_by(main_list) %>%\n", "    summarise(\n", "      n_accounts = n(),\n", "      .groups = \"drop\"\n", "    )\n", "  \n", "  table2_from_weekly <- table2_from_weekly %>%\n", "    left_join(account_counts, by = \"main_list\")\n", "} else {\n", "  if (\"n_accounts\" %in% names(weekly_data)) {\n", "    account_counts <- weekly_data %>%\n", "      group_by(main_list) %>%\n", "      summarise(\n", "        n_accounts = max(n_accounts, na.rm = TRUE),\n", "        .groups = \"drop\"\n", "      )\n", "    table2_from_weekly <- table2_from_weekly %>%\n", "      left_join(account_counts, by = \"main_list\")\n", "  } else {\n", "    table2_from_weekly$n_accounts <- NA\n", "  }\n", "}\n", "\n", "# Format Table 2 for working paper\n", "table2 <- data.frame(\n", "  Group = table2_from_weekly$main_list,\n", "  N_Accounts = ifelse(is.na(table2_from_weekly$n_accounts), NA, table2_from_weekly$n_accounts),\n", "  Total_Posts = table2_from_weekly$total_posts,\n", "  Avg_Views = round(table2_from_weekly$avg_views_overall, 0),\n", "  stringsAsFactors = FALSE\n", ")\n", "\n", "cat(\"TABLE 2 - Account and Post Counts by Group:\\n\\n\")\n", "print(table2, row.names = FALSE)\n", "cat(\"\\n\")\n", "\n", "# Save Table 2\n", "write.csv(table2, \"RQ1_Table2_account_post_counts.csv\", row.names = FALSE)\n", "cat(\"Saved: RQ1_Table2_account_post_counts.csv\\n\\n\")\n", "\n", "# ============================================================================\n", "# TABLE 3: WEEKLY AGGREGATED ENGAGEMENT STATISTICS\n", "# (Working Paper Table 3)\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"TABLE 3: WEEKLY AGGREGATED ENGAGEMENT STATISTICS\\n\")\n", "cat(\"(Working Paper Table 3)\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "# Calculate comprehensive engagement statistics by group\n", "table3_stats <- weekly_data %>%\n", "  group_by(main_list) %>%\n", "  summarise(\n", "    # Views\n", "    views_mean = mean(avg_views, na.rm = TRUE),\n", "    views_sd = sd(avg_views, na.rm = TRUE),\n", "    views_median = median(avg_views, na.rm = TRUE),\n", "    views_min = min(avg_views, na.rm = TRUE),\n", "    views_max = max(avg_views, na.rm = TRUE),\n", "    # Reactions\n", "    reactions_mean = mean(avg_reactions, na.rm = TRUE),\n", "    reactions_sd = sd(avg_reactions, na.rm = TRUE),\n", "    reactions_median = median(avg_reactions, na.rm = TRUE),\n", "    reactions_min = min(avg_reactions, na.rm = TRUE),\n", "    reactions_max = max(avg_reactions, na.rm = TRUE),\n", "    # Shares\n", "    shares_mean = mean(avg_shares, na.rm = TRUE),\n", "    shares_sd = sd(avg_shares, na.rm = TRUE),\n", "    shares_median = median(avg_shares, na.rm = TRUE),\n", "    shares_min = min(avg_shares, na.rm = TRUE),\n", "    shares_max = max(avg_shares, na.rm = TRUE),\n", "    # Comments\n", "    comments_mean = mean(avg_comments, na.rm = TRUE),\n", "    comments_sd = sd(avg_comments, na.rm = TRUE),\n", "    comments_median = median(avg_comments, na.rm = TRUE),\n", "    comments_min = min(avg_comments, na.rm = TRUE),\n", "    comments_max = max(avg_comments, na.rm = TRUE),\n", "    .groups = \"drop\"\n", "  )\n", "\n", "# Display Views\n", "cat(\"Views (Reach):\\n\")\n", "table3_views <- table3_stats %>%\n", "  transmute(\n", "    Group = main_list,\n", "    Mean = round(views_mean, 1),\n", "    SD = round(views_sd, 1),\n", "    Median = round(views_median, 1),\n", "    Min = round(views_min, 1),\n", "    Max = round(views_max, 1)\n", "  )\n", "print(as.data.frame(table3_views), row.names = FALSE)\n", "cat(\"\\n\")\n", "\n", "# Display Reactions\n", "cat(\"Reactions:\\n\")\n", "table3_reactions <- table3_stats %>%\n", "  transmute(\n", "    Group = main_list,\n", "    Mean = round(reactions_mean, 1),\n", "    SD = round(reactions_sd, 1),\n", "    Median = round(reactions_median, 1),\n", "    Min = round(reactions_min, 1),\n", "    Max = round(reactions_max, 1)\n", "  )\n", "print(as.data.frame(table3_reactions), row.names = FALSE)\n", "cat(\"\\n\")\n", "\n", "# Display Shares\n", "cat(\"Shares:\\n\")\n", "table3_shares <- table3_stats %>%\n", "  transmute(\n", "    Group = main_list,\n", "    Mean = round(shares_mean, 1),\n", "    SD = round(shares_sd, 1),\n", "    Median = round(shares_median, 1),\n", "    Min = round(shares_min, 1),\n", "    Max = round(shares_max, 1)\n", "  )\n", "print(as.data.frame(table3_shares), row.names = FALSE)\n", "cat(\"\\n\")\n", "\n", "# Display Comments\n", "cat(\"Comments:\\n\")\n", "table3_comments <- table3_stats %>%\n", "  transmute(\n", "    Group = main_list,\n", "    Mean = round(comments_mean, 1),\n", "    SD = round(comments_sd, 1),\n", "    Median = round(comments_median, 1),\n", "    Min = round(comments_min, 1),\n", "    Max = round(comments_max, 1)\n", "  )\n", "print(as.data.frame(table3_comments), row.names = FALSE)\n", "cat(\"\\n\")\n", "\n", "# Save Table 3 as CSV (long format)\n", "table3_long <- table3_stats %>%\n", "  pivot_longer(\n", "    cols = -main_list,\n", "    names_to = c(\"metric\", \"stat\"),\n", "    names_sep = \"_\",\n", "    values_to = \"value\"\n", "  ) %>%\n", "  pivot_wider(\n", "    names_from = stat,\n", "    values_from = value\n", "  ) %>%\n", "  rename(Group = main_list, Metric = metric)\n", "\n", "write.csv(table3_long, \"RQ1_Table3_engagement_stats.csv\", row.names = FALSE)\n", "cat(\"Saved: RQ1_Table3_engagement_stats.csv\\n\\n\")\n", "\n", "# ============================================================================\n", "# STEP 2: KEY DATES REFERENCE\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"STEP 2: KEY DATES REFERENCE\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "# Meta policy timeline\n", "meta_policy_dates <- data.frame(\n", "  date = as.Date(c(\n", "    \"2021-02-10\", \"2022-07-19\", \"2023-04-20\", \"2025-01-07\"\n", "  )),\n", "  event = c(\n", "    \"Initial announcement\",\n", "    \"Global implementation\",\n", "    \"Refinements (survey-based signals)\",\n", "    \"Policy reversal\"\n", "  ),\n", "  stringsAsFactors = FALSE\n", ")\n", "\n", "# Electoral events\n", "italian_election_date <- as.Date(\"2022-09-25\")\n", "italian_election_window_start <- as.Date(\"2022-08-01\")\n", "italian_election_window_end <- as.Date(\"2022-11-30\")\n", "\n", "eu_election_date <- as.Date(\"2024-06-09\")\n", "eu_election_window_start <- as.Date(\"2024-05-01\")\n", "eu_election_window_end <- as.Date(\"2024-07-31\")\n", "\n", "election_events <- data.frame(\n", "  election = c(\"Italian General Election 2022\", \"EU Parliamentary Election 2024\"),\n", "  date = c(italian_election_date, eu_election_date),\n", "  window_start = c(italian_election_window_start, eu_election_window_start),\n", "  window_end = c(italian_election_window_end, eu_election_window_end),\n", "  stringsAsFactors = FALSE\n", ")\n", "\n", "cat(\"META POLICY TIMELINE:\\n\")\n", "for (i in 1:nrow(meta_policy_dates)) {\n", "  cat(\"  \", as.character(meta_policy_dates$date[i]), \" - \", \n", "      meta_policy_dates$event[i], \"\\n\", sep = \"\")\n", "}\n", "cat(\"\\n\")\n", "\n", "cat(\"ELECTORAL EVENTS:\\n\")\n", "cat(\"  Italian General Election 2022:\", as.character(italian_election_date), \"\\n\")\n", "cat(\"  EU Parliamentary Election 2024:\", as.character(eu_election_date), \"\\n\\n\")\n", "\n", "# ============================================================================\n", "# STEP 3: BREAKPOINT DETECTION (Discovery Sample)\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"STEP 3: BREAKPOINT DETECTION (Discovery Sample)\\n\")\n", "cat(\"Discovery sample:\", discovery_group, \"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "# Extract discovery sample\n", "discovery_data <- weekly_data %>%\n", "  filter(main_list == discovery_group) %>%\n", "  arrange(week) %>%\n", "  mutate(time_index = row_number())\n", "\n", "cat(\"Discovery sample size:\", nrow(discovery_data), \"weeks\\n\\n\")\n", "\n", "# -----------------------------------------------------------------------------\n", "# 3.1 Bai-Perron Detection\n", "# -----------------------------------------------------------------------------\n", "\n", "cat(\"3.1 BAI-PERRON STRUCTURAL BREAK DETECTION\\n\")\n", "cat(rep(\"-\", 60), \"\\n\\n\", sep = \"\")\n", "\n", "detect_bai_perron <- function(data, metric, max_breaks = 3) {\n", "  \n", "  clean_data <- data %>%\n", "    filter(!is.na(.data[[metric]])) %>%\n", "    mutate(time_index = row_number())\n", "  \n", "  bp_result <- tryCatch({\n", "    breakpoints(\n", "      as.formula(paste(metric, \"~ 1\")),\n", "      data = clean_data,\n", "      h = 0.15,\n", "      breaks = max_breaks\n", "    )\n", "  }, error = function(e) {\n", "    cat(\"  Error for\", metric, \":\", e$message, \"\\n\")\n", "    return(NULL)\n", "  })\n", "  \n", "  if (is.null(bp_result) || is.na(bp_result$breakpoints[1])) {\n", "    return(NULL)\n", "  }\n", "  \n", "  break_indices <- bp_result$breakpoints\n", "  break_dates <- clean_data$week[break_indices]\n", "  \n", "  cat(\"  \", metric, \": \", length(break_dates), \" breakpoints detected\\n\", sep = \"\")\n", "  for (i in seq_along(break_dates)) {\n", "    cat(\"    Break\", i, \":\", as.character(break_dates[i]), \"\\n\")\n", "  }\n", "  \n", "  return(list(\n", "    dates = break_dates,\n", "    indices = break_indices,\n", "    metric = metric,\n", "    algorithm = \"Bai-Perron\"\n", "  ))\n", "}\n", "\n", "# Run Bai-Perron on all metrics\n", "bp_results <- list()\n", "for (metric in c(\"avg_views\", \"avg_reactions\", \"avg_shares\", \"avg_comments\")) {\n", "  bp_results[[metric]] <- detect_bai_perron(discovery_data, metric)\n", "}\n", "cat(\"\\n\")\n", "\n", "# -----------------------------------------------------------------------------\n", "# 3.2 PELT Detection\n", "# -----------------------------------------------------------------------------\n", "\n", "cat(\"3.2 PELT CHANGEPOINT DETECTION\\n\")\n", "cat(rep(\"-\", 60), \"\\n\\n\", sep = \"\")\n", "\n", "detect_pelt <- function(data, metric) {\n", "  \n", "  clean_data <- data %>%\n", "    filter(!is.na(.data[[metric]]))\n", "  \n", "  values <- clean_data[[metric]]\n", "  \n", "  pelt_result <- tryCatch({\n", "    cpt.meanvar(values, method = \"PELT\", penalty = \"BIC\")\n", "  }, error = function(e) {\n", "    cat(\"  Error for\", metric, \":\", e$message, \"\\n\")\n", "    return(NULL)\n", "  })\n", "  \n", "  if (is.null(pelt_result)) return(NULL)\n", "  \n", "  changepoints <- cpts(pelt_result)\n", "  \n", "  if (length(changepoints) == 0) {\n", "    cat(\"  \", metric, \": No changepoints detected\\n\", sep = \"\")\n", "    return(NULL)\n", "  }\n", "  \n", "  change_dates <- clean_data$week[changepoints]\n", "  \n", "  cat(\"  \", metric, \": \", length(change_dates), \" changepoints detected\\n\", sep = \"\")\n", "  for (i in seq_along(change_dates)) {\n", "    cat(\"    Changepoint\", i, \":\", as.character(change_dates[i]), \"\\n\")\n", "  }\n", "  \n", "  return(list(\n", "    dates = change_dates,\n", "    indices = changepoints,\n", "    metric = metric,\n", "    algorithm = \"PELT\"\n", "  ))\n", "}\n", "\n", "# Run PELT on all metrics\n", "pelt_results <- list()\n", "for (metric in c(\"avg_views\", \"avg_reactions\", \"avg_shares\", \"avg_comments\")) {\n", "  pelt_results[[metric]] <- detect_pelt(discovery_data, metric)\n", "}\n", "cat(\"\\n\")\n", "\n", "# -----------------------------------------------------------------------------\n", "# 3.3 Build Consensus\n", "# -----------------------------------------------------------------------------\n", "\n", "cat(\"3.3 BUILDING CONSENSUS BREAKPOINTS\\n\")\n", "cat(rep(\"-\", 60), \"\\n\\n\", sep = \"\")\n", "\n", "build_consensus_breakpoints <- function(bp_list, pelt_list, tolerance_days = 30) {\n", "  \n", "  all_detections <- data.frame()\n", "  \n", "  for (metric in names(bp_list)) {\n", "    if (!is.null(bp_list[[metric]])) {\n", "      all_detections <- rbind(all_detections, data.frame(\n", "        date = bp_list[[metric]]$dates,\n", "        metric = metric,\n", "        algorithm = \"Bai-Perron\",\n", "        stringsAsFactors = FALSE\n", "      ))\n", "    }\n", "  }\n", "  \n", "  for (metric in names(pelt_list)) {\n", "    if (!is.null(pelt_list[[metric]])) {\n", "      all_detections <- rbind(all_detections, data.frame(\n", "        date = pelt_list[[metric]]$dates,\n", "        metric = metric,\n", "        algorithm = \"PELT\",\n", "        stringsAsFactors = FALSE\n", "      ))\n", "    }\n", "  }\n", "  \n", "  if (nrow(all_detections) == 0) {\n", "    cat(\"No breakpoints detected by any method.\\n\")\n", "    return(NULL)\n", "  }\n", "  \n", "  all_detections <- all_detections %>%\n", "    mutate(date = as.Date(date)) %>%\n", "    arrange(date)\n", "  \n", "  cat(\"Total detections:\", nrow(all_detections), \"\\n\\n\")\n", "  \n", "  # Cluster nearby dates\n", "  all_detections <- all_detections %>%\n", "    mutate(cluster = cumsum(c(1, diff(date) > tolerance_days)))\n", "  \n", "  # Summarize clusters\n", "  consensus <- all_detections %>%\n", "    group_by(cluster) %>%\n", "    summarise(\n", "      consensus_date = median(date),\n", "      date_min = min(date),\n", "      date_max = max(date),\n", "      date_range_days = as.numeric(max(date) - min(date)),\n", "      n_methods = n(),\n", "      n_algorithms = n_distinct(algorithm),\n", "      has_bai_perron = any(algorithm == \"Bai-Perron\"),\n", "      has_pelt = any(algorithm == \"PELT\"),\n", "      metrics_bp = paste(unique(metric[algorithm == \"Bai-Perron\"]), collapse = \", \"),\n", "      metrics_pelt = paste(unique(metric[algorithm == \"PELT\"]), collapse = \", \"),\n", "      .groups = \"drop\"\n", "    ) %>%\n", "    mutate(\n", "      cross_validated = n_algorithms >= 2,\n", "      strength = case_when(\n", "        cross_validated & n_methods >= 6 ~ \"VERY STRONG\",\n", "        cross_validated & n_methods >= 4 ~ \"STRONG\",\n", "        cross_validated ~ \"MODERATE\",\n", "        n_methods >= 4 ~ \"Single-Algo (Many)\",\n", "        TRUE ~ \"WEAK\"\n", "      ),\n", "      date_range = ifelse(\n", "        date_min == date_max,\n", "        as.character(date_min),\n", "        paste(date_min, \"to\", date_max)\n", "      )\n", "    ) %>%\n", "    arrange(consensus_date)\n", "  \n", "  cat(\"CONSENSUS BREAKPOINTS:\\n\\n\")\n", "  for (i in 1:nrow(consensus)) {\n", "    cat(\"Cluster\", i, \":\\n\")\n", "    cat(\"  Consensus date:\", as.character(consensus$consensus_date[i]), \"\\n\")\n", "    cat(\"  Detection range:\", consensus$date_range[i], \"\\n\")\n", "    cat(\"  Methods:\", consensus$n_methods[i], \"| Algorithms:\", consensus$n_algorithms[i], \"\\n\")\n", "    cat(\"  Cross-Validated:\", ifelse(consensus$cross_validated[i], \"YES\", \"NO\"), \"\\n\")\n", "    cat(\"  Strength:\", consensus$strength[i], \"\\n\\n\")\n", "  }\n", "  \n", "  return(consensus)\n", "}\n", "\n", "consensus_breakpoints <- build_consensus_breakpoints(bp_results, pelt_results)\n", "\n", "# ============================================================================\n", "# TABLE 4: CROSS-VALIDATED BREAKPOINTS\n", "# (Working Paper Table 4)\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"TABLE 4: CROSS-VALIDATED BREAKPOINTS\\n\")\n", "cat(\"(Working Paper Table 4)\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "# Get cross-validated breakpoints\n", "cross_validated <- consensus_breakpoints %>%\n", "  filter(cross_validated == TRUE) %>%\n", "  arrange(consensus_date)\n", "\n", "if (nrow(cross_validated) == 0) {\n", "  cat(\"WARNING: No cross-validated breakpoints found!\\n\")\n", "  cross_validated <- consensus_breakpoints %>%\n", "    filter(n_methods >= 4) %>%\n", "    arrange(consensus_date)\n", "}\n", "\n", "# Assign final breakpoints (T1, T2, T3)\n", "assign_final_breakpoints <- function(cv_bp) {\n", "  \n", "  n_bp <- nrow(cv_bp)\n", "  \n", "  if (n_bp == 0) {\n", "    stop(\"No breakpoints available for analysis!\")\n", "  }\n", "  \n", "  create_bp_struct <- function(row) {\n", "    if (is.null(row) || nrow(row) == 0) return(NULL)\n", "    list(\n", "      date = as.Date(row$consensus_date),\n", "      date_min = as.Date(row$date_min),\n", "      date_max = as.Date(row$date_max),\n", "      date_range_days = row$date_range_days,\n", "      methods = row$n_methods,\n", "      n_algorithms = row$n_algorithms,\n", "      cross_validated = row$cross_validated,\n", "      strength = row$strength,\n", "      date_range = row$date_range\n", "    )\n", "  }\n", "  \n", "  breakpoints <- list()\n", "  selected_indices <- c()\n", "  \n", "  if (n_bp >= 1) {\n", "    breakpoints$T1 <- create_bp_struct(cv_bp[1, ])\n", "    selected_indices <- c(selected_indices, 1)\n", "  }\n", "  \n", "  if (n_bp >= 3) {\n", "    reversal_candidates <- cv_bp %>% \n", "      mutate(row_idx = row_number()) %>%\n", "      filter(consensus_date >= as.Date(\"2024-09-01\"))\n", "    \n", "    if (nrow(reversal_candidates) > 0) {\n", "      selected_idx <- reversal_candidates$row_idx[1]\n", "      breakpoints$T3 <- create_bp_struct(cv_bp[selected_idx, ])\n", "      selected_indices <- c(selected_indices, selected_idx)\n", "    } else {\n", "      breakpoints$T3 <- create_bp_struct(cv_bp[n_bp, ])\n", "      selected_indices <- c(selected_indices, n_bp)\n", "    }\n", "    \n", "    middle_candidates <- cv_bp %>%\n", "      mutate(row_idx = row_number()) %>%\n", "      filter(consensus_date > breakpoints$T1$date,\n", "             consensus_date < breakpoints$T3$date) %>%\n", "      arrange(desc(n_methods), consensus_date)\n", "    \n", "    if (nrow(middle_candidates) > 0) {\n", "      selected_idx <- middle_candidates$row_idx[1]\n", "      breakpoints$T2 <- create_bp_struct(cv_bp[selected_idx, ])\n", "      selected_indices <- c(selected_indices, selected_idx)\n", "    } else {\n", "      breakpoints$T2 <- NULL\n", "    }\n", "    \n", "  } else if (n_bp == 2) {\n", "    breakpoints$T3 <- create_bp_struct(cv_bp[2, ])\n", "    selected_indices <- c(selected_indices, 2)\n", "    breakpoints$T2 <- NULL\n", "  } else {\n", "    breakpoints$T2 <- NULL\n", "    breakpoints$T3 <- NULL\n", "  }\n", "  \n", "  return(breakpoints)\n", "}\n", "\n", "FINAL_BREAKPOINTS <- assign_final_breakpoints(cross_validated)\n", "\n", "# Create Table 4 data frame\n", "table4_data <- data.frame(\n", "  Breakpoint = character(),\n", "  Point_Estimate = character(),\n", "  Methods = numeric(),\n", "  Strength = character(),\n", "  Detection_Range = character(),\n", "  stringsAsFactors = FALSE\n", ")\n", "\n", "if (!is.null(FINAL_BREAKPOINTS$T1)) {\n", "  table4_data <- rbind(table4_data, data.frame(\n", "    Breakpoint = \"T1 (Implementation)\",\n", "    Point_Estimate = as.character(FINAL_BREAKPOINTS$T1$date),\n", "    Methods = FINAL_BREAKPOINTS$T1$methods,\n", "    Strength = FINAL_BREAKPOINTS$T1$strength,\n", "    Detection_Range = FINAL_BREAKPOINTS$T1$date_range,\n", "    stringsAsFactors = FALSE\n", "  ))\n", "}\n", "\n", "if (!is.null(FINAL_BREAKPOINTS$T2)) {\n", "  table4_data <- rbind(table4_data, data.frame(\n", "    Breakpoint = \"T2 (Adjustment)\",\n", "    Point_Estimate = as.character(FINAL_BREAKPOINTS$T2$date),\n", "    Methods = FINAL_BREAKPOINTS$T2$methods,\n", "    Strength = FINAL_BREAKPOINTS$T2$strength,\n", "    Detection_Range = FINAL_BREAKPOINTS$T2$date_range,\n", "    stringsAsFactors = FALSE\n", "  ))\n", "}\n", "\n", "if (!is.null(FINAL_BREAKPOINTS$T3)) {\n", "  table4_data <- rbind(table4_data, data.frame(\n", "    Breakpoint = \"T3 (Reversal)\",\n", "    Point_Estimate = as.character(FINAL_BREAKPOINTS$T3$date),\n", "    Methods = FINAL_BREAKPOINTS$T3$methods,\n", "    Strength = FINAL_BREAKPOINTS$T3$strength,\n", "    Detection_Range = FINAL_BREAKPOINTS$T3$date_range,\n", "    stringsAsFactors = FALSE\n", "  ))\n", "}\n", "\n", "cat(\"TABLE 4 - Cross-Validated Breakpoints:\\n\\n\")\n", "print(table4_data, row.names = FALSE)\n", "cat(\"\\n\")\n", "\n", "write.csv(table4_data, \"RQ1_Table4_breakpoints.csv\", row.names = FALSE)\n", "cat(\"Saved: RQ1_Table4_breakpoints.csv\\n\\n\")\n", "\n", "# Determine model type\n", "MODEL_TYPE <- case_when(\n", "  !is.null(FINAL_BREAKPOINTS$T2) ~ \"THREE_BREAKPOINT\",\n", "  !is.null(FINAL_BREAKPOINTS$T3) ~ \"TWO_BREAKPOINT\",\n", "  TRUE ~ \"ONE_BREAKPOINT\"\n", ")\n", "\n", "cat(\"MODEL TYPE:\", MODEL_TYPE, \"\\n\\n\")\n", "\n", "# ============================================================================\n", "# STEP 4: APPLY PHASES TO ALL DATA\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"STEP 4: APPLY PHASES TO ALL DATA\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "apply_phases <- function(data, breakpoints, model_type) {\n", "  \n", "  T1 <- breakpoints$T1$date\n", "  T2 <- if (!is.null(breakpoints$T2)) breakpoints$T2$date else NULL\n", "  T3 <- if (!is.null(breakpoints$T3)) breakpoints$T3$date else NULL\n", "  \n", "  if (model_type == \"THREE_BREAKPOINT\") {\n", "    data <- data %>%\n", "      mutate(\n", "        phase = case_when(\n", "          week < T1 ~ \"0_Pre-Policy\",\n", "          week >= T1 & week < T2 ~ \"1_Policy-Active\",\n", "          week >= T2 & week < T3 ~ \"2_Adjusted-Policy\",\n", "          week >= T3 ~ \"3_Post-Reversal\"\n", "        ),\n", "        phase = factor(phase, levels = c(\n", "          \"0_Pre-Policy\", \"1_Policy-Active\", \"2_Adjusted-Policy\", \"3_Post-Reversal\"\n", "        ))\n", "      )\n", "  } else if (model_type == \"TWO_BREAKPOINT\") {\n", "    data <- data %>%\n", "      mutate(\n", "        phase = case_when(\n", "          week < T1 ~ \"0_Pre-Policy\",\n", "          week >= T1 & week < T3 ~ \"1_Policy-Active\",\n", "          week >= T3 ~ \"2_Post-Reversal\"\n", "        ),\n", "        phase = factor(phase, levels = c(\n", "          \"0_Pre-Policy\", \"1_Policy-Active\", \"2_Post-Reversal\"\n", "        ))\n", "      )\n", "  } else {\n", "    data <- data %>%\n", "      mutate(\n", "        phase = case_when(\n", "          week < T1 ~ \"0_Pre-Policy\",\n", "          TRUE ~ \"1_Policy-Active\"\n", "        ),\n", "        phase = factor(phase, levels = c(\"0_Pre-Policy\", \"1_Policy-Active\"))\n", "      )\n", "  }\n", "  \n", "  # Add election indicators\n", "  data <- data %>%\n", "    mutate(\n", "      in_italian_election_window = week >= italian_election_window_start & \n", "                                    week <= italian_election_window_end,\n", "      in_eu_election_window = week >= eu_election_window_start & \n", "                              week <= eu_election_window_end,\n", "      in_any_election_window = in_italian_election_window | in_eu_election_window\n", "    )\n", "  \n", "  return(data)\n", "}\n", "\n", "weekly_data_phased <- apply_phases(weekly_data, FINAL_BREAKPOINTS, MODEL_TYPE)\n", "discovery_data_phased <- weekly_data_phased %>%\n", "  filter(main_list == discovery_group)\n", "\n", "# ============================================================================\n", "# TABLE 5: REACH STATISTICS BY POLICY PHASE (Re-elected MPs)\n", "# (Working Paper Table 5)\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"TABLE 5: REACH STATISTICS BY POLICY PHASE (\", discovery_group, \")\\n\", sep = \"\")\n", "cat(\"(Working Paper Table 5)\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "table5_stats <- discovery_data_phased %>%\n", "  group_by(phase) %>%\n", "  summarise(\n", "    n_weeks = n(),\n", "    mean_views = mean(avg_views, na.rm = TRUE),\n", "    median_views = median(avg_views, na.rm = TRUE),\n", "    sd_views = sd(avg_views, na.rm = TRUE),\n", "    .groups = \"drop\"\n", "  ) %>%\n", "  arrange(phase)\n", "\n", "# Calculate change from previous phase\n", "table5_stats <- table5_stats %>%\n", "  mutate(\n", "    change_pct = 100 * (mean_views - lag(mean_views)) / lag(mean_views)\n", "  )\n", "\n", "# Format Table 5\n", "table5 <- table5_stats %>%\n", "  transmute(\n", "    Phase = phase,\n", "    N_Weeks = n_weeks,\n", "    Mean_Views = round(mean_views, 0),\n", "    Median_Views = round(median_views, 0),\n", "    SD = round(sd_views, 0),\n", "    Change = ifelse(is.na(change_pct), \"\u2014\", sprintf(\"%+.1f%%\", change_pct))\n", "  )\n", "\n", "cat(\"TABLE 5 - Reach Statistics by Policy Phase:\\n\\n\")\n", "print(as.data.frame(table5), row.names = FALSE)\n", "cat(\"\\n\")\n", "\n", "write.csv(table5, \"RQ1_Table5_reach_by_phase.csv\", row.names = FALSE)\n", "cat(\"Saved: RQ1_Table5_reach_by_phase.csv\\n\\n\")\n", "\n", "# ============================================================================\n", "# TABLE 6: ENGAGEMENT METRICS BY POLICY PHASE (Re-elected MPs)\n", "# (Working Paper Table 6)\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"TABLE 6: ENGAGEMENT METRICS BY POLICY PHASE (\", discovery_group, \")\\n\", sep = \"\")\n", "cat(\"(Working Paper Table 6)\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "table6_engagement <- discovery_data_phased %>%\n", "  filter(!is.na(phase)) %>%\n", "  group_by(phase) %>%\n", "  summarise(\n", "    Reactions_Mean = round(mean(avg_reactions, na.rm = TRUE), 1),\n", "    Shares_Mean = round(mean(avg_shares, na.rm = TRUE), 1),\n", "    Comments_Mean = round(mean(avg_comments, na.rm = TRUE), 1),\n", "    .groups = \"drop\"\n", "  ) %>%\n", "  arrange(phase)\n", "\n", "cat(\"TABLE 6 - Engagement Metrics by Phase:\\n\\n\")\n", "print(as.data.frame(table6_engagement), row.names = FALSE)\n", "cat(\"\\n\")\n", "\n", "write.csv(table6_engagement, \"RQ1_Table6_engagement_by_phase.csv\", row.names = FALSE)\n", "cat(\"Saved: RQ1_Table6_engagement_by_phase.csv\\n\\n\")\n", "\n", "# ============================================================================\n", "# TABLE 7: BREAKPOINT VALIDATION ACROSS GROUPS\n", "# (Working Paper Table 7)\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"TABLE 7: BREAKPOINT VALIDATION ACROSS GROUPS\\n\")\n", "cat(\"(Working Paper Table 7)\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "validation_results <- data.frame()\n", "\n", "for (group in c(discovery_group, validation_groups)) {\n", "  \n", "  group_data <- weekly_data_phased %>%\n", "    filter(main_list == group, !is.na(phase))\n", "  \n", "  if (nrow(group_data) == 0) next\n", "  \n", "  # Calculate phase stats\n", "  group_phase_stats <- group_data %>%\n", "    group_by(phase) %>%\n", "    summarise(mean_views = mean(avg_views, na.rm = TRUE), .groups = \"drop\") %>%\n", "    arrange(phase)\n", "  \n", "  # Calculate transitions\n", "  group_means <- group_phase_stats$mean_views\n", "  group_directions <- c()\n", "  \n", "  for (i in 2:length(group_means)) {\n", "    direction <- ifelse(group_means[i] > group_means[i-1], \"UP\", \"DOWN\")\n", "    group_directions <- c(group_directions, direction)\n", "  }\n", "  \n", "  pattern <- paste(group_directions, collapse = \" \u2192 \")\n", "  \n", "  # Check key transitions\n", "  T1_correct <- length(group_directions) >= 1 && group_directions[1] == \"DOWN\"\n", "  T3_correct <- length(group_directions) >= 1 && group_directions[length(group_directions)] == \"UP\"\n", "  \n", "  # Kruskal-Wallis test\n", "  kw_test <- kruskal.test(avg_views ~ phase, data = group_data)\n", "  \n", "  validation_results <- rbind(validation_results, data.frame(\n", "    Group = group,\n", "    Pattern = pattern,\n", "    T1_Valid = ifelse(T1_correct, \"\u2713\", \"\u2717\"),\n", "    T3_Valid = ifelse(T3_correct, \"\u2713\", \"\u2717\"),\n", "    KW_p = format.pval(kw_test$p.value, digits = 3),\n", "    stringsAsFactors = FALSE\n", "  ))\n", "}\n", "\n", "cat(\"TABLE 7 - Breakpoint Validation Across Groups:\\n\\n\")\n", "print(validation_results, row.names = FALSE)\n", "cat(\"\\n\")\n", "\n", "write.csv(validation_results, \"RQ1_Table7_validation.csv\", row.names = FALSE)\n", "cat(\"Saved: RQ1_Table7_validation.csv\\n\\n\")\n", "\n", "# ============================================================================\n", "# TABLE 8: CROSS-GROUP MAGNITUDE COMPARISON (VIEWS)\n", "# (Working Paper Table 8)\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"TABLE 8: CROSS-GROUP MAGNITUDE COMPARISON (VIEWS)\\n\")\n", "cat(\"(Working Paper Table 8)\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "table8_data <- data.frame()\n", "\n", "for (group in unique(weekly_data_phased$main_list)) {\n", "  \n", "  group_stats <- weekly_data_phased %>%\n", "    filter(main_list == group, !is.na(phase)) %>%\n", "    group_by(phase) %>%\n", "    summarise(mean_views = mean(avg_views, na.rm = TRUE), .groups = \"drop\") %>%\n", "    arrange(phase)\n", "  \n", "  # Extract phase values\n", "  phase0 <- group_stats$mean_views[group_stats$phase == \"0_Pre-Policy\"]\n", "  phase1 <- group_stats$mean_views[group_stats$phase == \"1_Policy-Active\"]\n", "  phase2 <- group_stats$mean_views[group_stats$phase == \"2_Adjusted-Policy\"]\n", "  phase3 <- group_stats$mean_views[group_stats$phase == \"3_Post-Reversal\"]\n", "  \n", "  if (length(phase0) == 0) phase0 <- NA\n", "  if (length(phase1) == 0) phase1 <- NA\n", "  if (length(phase2) == 0) phase2 <- NA\n", "  if (length(phase3) == 0) phase3 <- NA\n", "  \n", "  # Calculate delta (baseline to trough)\n", "  trough <- min(c(phase1, phase2), na.rm = TRUE)\n", "  if (is.infinite(trough)) trough <- phase1\n", "  \n", "  delta1 <- if (!is.na(phase0) && !is.na(trough)) {\n", "    100 * (trough - phase0) / phase0\n", "  } else NA\n", "  \n", "  table8_data <- rbind(table8_data, data.frame(\n", "    Group = group,\n", "    Phase_0 = round(phase0, 0),\n", "    Phase_1 = round(phase1, 0),\n", "    Phase_2 = round(phase2, 0),\n", "    Phase_3 = round(phase3, 0),\n", "    Delta = delta1,\n", "    stringsAsFactors = FALSE\n", "  ))\n", "}\n", "\n", "# Format for display\n", "table8_display <- table8_data %>%\n", "  mutate(\n", "    Phase_0 = format(Phase_0, big.mark = \",\"),\n", "    Phase_1 = format(Phase_1, big.mark = \",\"),\n", "    Phase_2 = format(Phase_2, big.mark = \",\"),\n", "    Phase_3 = format(Phase_3, big.mark = \",\"),\n", "    Delta = sprintf(\"%.1f%%\", Delta)\n", "  )\n", "\n", "cat(\"TABLE 8 - Cross-Group Magnitude Comparison:\\n\\n\")\n", "print(as.data.frame(table8_display), row.names = FALSE)\n", "cat(\"\\n\")\n", "\n", "write.csv(table8_data, \"RQ1_Table8_cross_group.csv\", row.names = FALSE)\n", "cat(\"Saved: RQ1_Table8_cross_group.csv\\n\\n\")\n", "\n", "# ============================================================================\n", "# TABLE 9: PAIRWISE PHASE COMPARISONS (DUNN'S TEST)\n", "# (Working Paper Table 9)\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"TABLE 9: PAIRWISE PHASE COMPARISONS (DUNN'S TEST)\\n\")\n", "cat(\"(Working Paper Table 9)\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "if (!require(dunn.test, quietly = TRUE)) {\n", "  install.packages(\"dunn.test\", repos = \"https://cloud.r-project.org\")\n", "  library(dunn.test)\n", "}\n", "\n", "pairwise_results <- list()\n", "\n", "for (group in unique(weekly_data_phased$main_list)) {\n", "  group_data <- weekly_data_phased %>% filter(main_list == group, !is.na(phase))\n", "  \n", "  cat(\"===\", group, \"===\\n\")\n", "  \n", "  dunn_result <- dunn.test(group_data$avg_views, group_data$phase, \n", "                           method = \"bonferroni\", kw = FALSE, \n", "                           table = FALSE, list = TRUE)\n", "  \n", "  comparisons <- data.frame(\n", "    comparison = dunn_result$comparisons,\n", "    Z = round(dunn_result$Z, 3),\n", "    p_adj = dunn_result$P.adjusted,\n", "    sig = ifelse(dunn_result$P.adjusted < 0.001, \"***\",\n", "                 ifelse(dunn_result$P.adjusted < 0.01, \"**\",\n", "                        ifelse(dunn_result$P.adjusted < 0.05, \"*\", \"n.s.\")))\n", "  )\n", "  \n", "  print(comparisons)\n", "  cat(\"\\n\")\n", "  \n", "  pairwise_results[[group]] <- comparisons\n", "}\n", "\n", "# Create summary table\n", "key_comparisons <- c(\"0_Pre-Policy - 1_Policy-Active\",\n", "                     \"0_Pre-Policy - 2_Adjusted-Policy\",\n", "                     \"1_Policy-Active - 2_Adjusted-Policy\",\n", "                     \"2_Adjusted-Policy - 3_Post-Reversal\",\n", "                     \"0_Pre-Policy - 3_Post-Reversal\")\n", "\n", "summary_matrix <- matrix(NA, nrow = length(key_comparisons), \n", "                         ncol = length(unique(weekly_data_phased$main_list)))\n", "colnames(summary_matrix) <- unique(weekly_data_phased$main_list)\n", "rownames(summary_matrix) <- c(\"Phase 0 vs 1\", \"Phase 0 vs 2\", \n", "                               \"Phase 1 vs 2\", \"Phase 2 vs 3\", \"Phase 0 vs 3\")\n", "\n", "for (i in seq_along(unique(weekly_data_phased$main_list))) {\n", "  group <- unique(weekly_data_phased$main_list)[i]\n", "  if (!is.null(pairwise_results[[group]])) {\n", "    for (j in seq_along(key_comparisons)) {\n", "      idx <- which(pairwise_results[[group]]$comparison == key_comparisons[j])\n", "      if (length(idx) > 0) {\n", "        summary_matrix[j, i] <- pairwise_results[[group]]$sig[idx]\n", "      }\n", "    }\n", "  }\n", "}\n", "\n", "cat(\"\\nTABLE 9 - Summary Matrix:\\n\\n\")\n", "print(summary_matrix)\n", "cat(\"\\n\")\n", "\n", "table9_df <- as.data.frame(summary_matrix)\n", "table9_df$Comparison <- rownames(summary_matrix)\n", "table9_df <- table9_df[, c(\"Comparison\", colnames(summary_matrix))]\n", "write.csv(table9_df, \"RQ1_Table9_pairwise.csv\", row.names = FALSE)\n", "cat(\"Saved: RQ1_Table9_pairwise.csv\\n\\n\")\n", "\n", "# ============================================================================\n", "# TABLE 10: PER-POST VS TOTAL WEEKLY REACH BY GROUP\n", "# (Working Paper Table 10)\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"TABLE 10: PER-POST VS TOTAL WEEKLY REACH BY GROUP\\n\")\n", "cat(\"(Working Paper Table 10)\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "# Calculate total weekly reach\n", "total_reach_weekly <- weekly_data_phased %>%\n", "  filter(!is.na(phase)) %>%\n", "  mutate(\n", "    total_weekly_views = avg_views * n_posts\n", "  )\n", "\n", "# Summary by group and phase\n", "total_reach_by_phase <- total_reach_weekly %>%\n", "  group_by(main_list, phase) %>%\n", "  summarise(\n", "    mean_total_views = mean(total_weekly_views, na.rm = TRUE),\n", "    .groups = \"drop\"\n", "  )\n", "\n", "# Create Table 10\n", "table10_data <- data.frame()\n", "\n", "for (group in unique(total_reach_by_phase$main_list)) {\n", "  group_data <- total_reach_by_phase %>% filter(main_list == group)\n", "  \n", "  # Per-post metrics from table8\n", "  perpost_phase0 <- table8_data$Phase_0[table8_data$Group == group]\n", "  perpost_phase2 <- table8_data$Phase_2[table8_data$Group == group]\n", "  \n", "  # Total metrics\n", "  total_phase0 <- group_data$mean_total_views[group_data$phase == \"0_Pre-Policy\"]\n", "  total_phase2 <- group_data$mean_total_views[group_data$phase == \"2_Adjusted-Policy\"]\n", "  \n", "  if (length(total_phase0) == 0) total_phase0 <- NA\n", "  if (length(total_phase2) == 0) total_phase2 <- NA\n", "  \n", "  # Calculate deltas\n", "  perpost_delta <- if (!is.na(perpost_phase0) && !is.na(perpost_phase2) && perpost_phase0 > 0) {\n", "    100 * (perpost_phase2 - perpost_phase0) / perpost_phase0\n", "  } else NA\n", "  \n", "  total_delta <- if (!is.na(total_phase0) && !is.na(total_phase2) && total_phase0 > 0) {\n", "    100 * (total_phase2 - total_phase0) / total_phase0\n", "  } else NA\n", "  \n", "  table10_data <- rbind(table10_data, data.frame(\n", "    Group = group,\n", "    PerPost_Phase0 = round(perpost_phase0, 0),\n", "    PerPost_Phase2 = round(perpost_phase2, 0),\n", "    PerPost_Delta = perpost_delta,\n", "    Total_Phase0 = round(total_phase0 / 1e6, 1),\n", "    Total_Phase2 = round(total_phase2 / 1e6, 1),\n", "    Total_Delta = total_delta,\n", "    stringsAsFactors = FALSE\n", "  ))\n", "}\n", "\n", "# Format for display\n", "table10_display <- table10_data %>%\n", "  mutate(\n", "    PerPost_Phase0 = format(PerPost_Phase0, big.mark = \",\"),\n", "    PerPost_Phase2 = format(PerPost_Phase2, big.mark = \",\"),\n", "    PerPost_Delta = sprintf(\"%.1f%%\", PerPost_Delta),\n", "    Total_Phase0 = paste0(Total_Phase0, \"M\"),\n", "    Total_Phase2 = paste0(Total_Phase2, \"M\"),\n", "    Total_Delta = sprintf(\"%+.1f%%\", Total_Delta)\n", "  )\n", "\n", "cat(\"TABLE 10 - Per-Post vs Total Weekly Reach:\\n\\n\")\n", "print(as.data.frame(table10_display), row.names = FALSE)\n", "cat(\"\\n\")\n", "\n", "write.csv(table10_data, \"RQ1_Table10_perpost_vs_total.csv\", row.names = FALSE)\n", "cat(\"Saved: RQ1_Table10_perpost_vs_total.csv\\n\\n\")\n", "\n", "# ============================================================================\n", "# FIGURE 1: TIME SERIES (ALL GROUPS)\n", "# (Working Paper Figure 1)\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"CREATING FIGURES FOR WORKING PAPER\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "T1 <- FINAL_BREAKPOINTS$T1$date\n", "T2 <- if (!is.null(FINAL_BREAKPOINTS$T2)) FINAL_BREAKPOINTS$T2$date else NULL\n", "T3 <- if (!is.null(FINAL_BREAKPOINTS$T3)) FINAL_BREAKPOINTS$T3$date else NULL\n", "\n", "# Figure 1: Main time series\n", "figure1 <- ggplot(weekly_data, aes(x = week, y = avg_views, color = main_list)) +\n", "  geom_line(linewidth = 0.8, alpha = 0.8) +\n", "  geom_smooth(method = \"loess\", span = 0.2, se = FALSE, linewidth = 1.5) +\n", "  geom_vline(xintercept = as.numeric(T1), linetype = \"dashed\", color = \"red\", linewidth = 1) +\n", "  annotate(\"text\", x = T1, y = Inf, label = \"T\u2081: Policy\\nImplementation\", \n", "           vjust = 1.5, hjust = -0.1, color = \"red\", fontface = \"bold\", size = 3)\n", "\n", "if (!is.null(T2)) {\n", "  figure1 <- figure1 +\n", "    geom_vline(xintercept = as.numeric(T2), linetype = \"dashed\", color = \"orange\", linewidth = 1) +\n", "    annotate(\"text\", x = T2, y = Inf, label = \"T\u2082: Adjustment\", \n", "             vjust = 1.5, hjust = -0.1, color = \"orange\", fontface = \"bold\", size = 3)\n", "}\n", "\n", "if (!is.null(T3)) {\n", "  figure1 <- figure1 +\n", "    geom_vline(xintercept = as.numeric(T3), linetype = \"dashed\", color = \"darkgreen\", linewidth = 1) +\n", "    annotate(\"text\", x = T3, y = Inf, label = \"T\u2083: Policy\\nReversal\", \n", "             vjust = 1.5, hjust = -0.1, color = \"darkgreen\", fontface = \"bold\", size = 3)\n", "}\n", "\n", "figure1 <- figure1 +\n", "  scale_y_continuous(labels = scales::comma) +\n", "  scale_color_brewer(palette = \"Set1\") +\n", "  labs(\n", "    title = \"RQ1: Meta's Political Content Policy Effects on Italian Political Actors\",\n", "    subtitle = paste0(\"Breakpoints: T\u2081 = \", as.character(T1),\n", "                      if (!is.null(T2)) paste0(\", T\u2082 = \", as.character(T2)) else \"\",\n", "                      if (!is.null(T3)) paste0(\", T\u2083 = \", as.character(T3)) else \"\",\n", "                      \" | Shaded regions indicate policy phases\"),\n", "    x = \"Date\",\n", "    y = \"Average Views per Post\",\n", "    color = \"Group\"\n", "  ) +\n", "  theme_minimal(base_size = 12) +\n", "  theme(\n", "    plot.title = element_text(face = \"bold\", size = 14),\n", "    plot.subtitle = element_text(size = 10, color = \"gray40\"),\n", "    legend.position = \"bottom\"\n", "  )\n", "\n", "ggsave(\"RQ1_Figure1_timeseries.png\", figure1, width = 14, height = 8, dpi = 300)\n", "cat(\"Saved: RQ1_Figure1_timeseries.png (Working Paper Figure 1)\\n\")\n", "\n", "# ============================================================================\n", "# FIGURE 2: MPs REELECTED TRENDS\n", "# (Working Paper Figure 2)\n", "# ============================================================================\n", "\n", "discovery_data_plot <- weekly_data_phased %>% filter(main_list == discovery_group)\n", "\n", "# Calculate phase means for annotation\n", "phase_means <- discovery_data_plot %>%\n", "  group_by(phase) %>%\n", "  summarise(\n", "    mean_views = mean(avg_views, na.rm = TRUE),\n", "    mid_date = median(week),\n", "    .groups = \"drop\"\n", "  )\n", "\n", "figure2 <- ggplot(discovery_data_plot, aes(x = week, y = avg_views)) +\n", "  geom_line(color = \"steelblue\", linewidth = 0.6, alpha = 0.7) +\n", "  geom_smooth(method = \"loess\", span = 0.15, se = TRUE, \n", "              color = \"navy\", fill = \"lightblue\", linewidth = 1.2) +\n", "  geom_vline(xintercept = as.numeric(T1), linetype = \"dashed\", color = \"red\", linewidth = 1)\n", "\n", "if (!is.null(T2)) {\n", "  figure2 <- figure2 +\n", "    geom_vline(xintercept = as.numeric(T2), linetype = \"dashed\", color = \"orange\", linewidth = 1)\n", "}\n", "\n", "if (!is.null(T3)) {\n", "  figure2 <- figure2 +\n", "    geom_vline(xintercept = as.numeric(T3), linetype = \"dashed\", color = \"darkgreen\", linewidth = 1)\n", "}\n", "\n", "# Add phase mean annotations\n", "for (i in 1:nrow(phase_means)) {\n", "  figure2 <- figure2 + \n", "    annotate(\"text\", \n", "             x = phase_means$mid_date[i], \n", "             y = max(discovery_data_plot$avg_views, na.rm = TRUE) * 0.95,\n", "             label = paste0(\"Mean: \", format(round(phase_means$mean_views[i], 0), big.mark = \",\")),\n", "             color = \"gray30\", size = 3, fontface = \"italic\")\n", "}\n", "\n", "figure2 <- figure2 +\n", "  scale_y_continuous(labels = scales::comma) +\n", "  labs(\n", "    title = paste0(\"RQ1: Reach Trends for \", discovery_group),\n", "    subtitle = paste0(\"T\u2081 = \", as.character(T1), \n", "                      if (!is.null(T2)) paste0(\" | T\u2082 = \", as.character(T2)) else \"\",\n", "                      if (!is.null(T3)) paste0(\" | T\u2083 = \", as.character(T3)) else \"\",\n", "                      \"\\nShaded: Gray = Pre-Policy, Red = Policy Active, Green = Post-Reversal\"),\n", "    x = \"Date\",\n", "    y = \"Average Views per Post\"\n", "  ) +\n", "  theme_minimal(base_size = 12) +\n", "  theme(\n", "    plot.title = element_text(face = \"bold\", size = 14)\n", "  )\n", "\n", "ggsave(\"RQ1_Figure2_discovery.png\", figure2, width = 12, height = 6, dpi = 300)\n", "cat(\"Saved: RQ1_Figure2_discovery.png (Working Paper Figure 2)\\n\")\n", "\n", "# ============================================================================\n", "# FIGURE 3: INDIVIDUAL GROUP TRENDS (FACETED)\n", "# (Working Paper Figure 3)\n", "# ============================================================================\n", "\n", "figure3 <- ggplot(weekly_data_phased, aes(x = week, y = avg_views)) +\n", "  geom_line(color = \"steelblue\", linewidth = 0.5, alpha = 0.6) +\n", "  geom_smooth(method = \"loess\", span = 0.2, se = FALSE, color = \"navy\", linewidth = 1) +\n", "  geom_vline(xintercept = as.numeric(T1), linetype = \"dashed\", color = \"red\", linewidth = 0.8)\n", "\n", "if (!is.null(T2)) {\n", "  figure3 <- figure3 +\n", "    geom_vline(xintercept = as.numeric(T2), linetype = \"dashed\", color = \"orange\", linewidth = 0.8)\n", "}\n", "\n", "if (!is.null(T3)) {\n", "  figure3 <- figure3 +\n", "    geom_vline(xintercept = as.numeric(T3), linetype = \"dashed\", color = \"darkgreen\", linewidth = 0.8)\n", "}\n", "\n", "figure3 <- figure3 +\n", "  facet_wrap(~main_list, scales = \"free_y\", ncol = 2) +\n", "  scale_y_continuous(labels = scales::comma) +\n", "  labs(\n", "    title = \"RQ1: Reach Trends by Group (Breakpoint Validation)\",\n", "    subtitle = paste0(\"T\u2081 = \", as.character(T1), \" (red)\",\n", "                      if (!is.null(T2)) paste0(\" | T\u2082 = \", as.character(T2), \" (orange)\") else \"\",\n", "                      if (!is.null(T3)) paste0(\" | T\u2083 = \", as.character(T3), \" (green)\") else \"\"),\n", "    x = \"Date\",\n", "    y = \"Average Views per Post\"\n", "  ) +\n", "  theme_minimal() +\n", "  theme(\n", "    plot.title = element_text(face = \"bold\"),\n", "    strip.text = element_text(face = \"bold\")\n", "  )\n", "\n", "ggsave(\"RQ1_Figure3_faceted.png\", figure3, width = 12, height = 10, dpi = 300)\n", "cat(\"Saved: RQ1_Figure3_faceted.png (Working Paper Figure 3)\\n\\n\")\n", "\n", "# ============================================================================\n", "# SUMMARY OF KEY FINDINGS\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"SUMMARY OF KEY FINDINGS FOR WORKING PAPER\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "# Calculate key statistics\n", "baseline_mean <- table5_stats$mean_views[1]\n", "trough_mean <- min(table5_stats$mean_views[table5_stats$phase %in% c(\"1_Policy-Active\", \"2_Adjusted-Policy\")], na.rm = TRUE)\n", "post_reversal_mean <- table5_stats$mean_views[nrow(table5_stats)]\n", "\n", "decline_from_baseline <- 100 * (trough_mean - baseline_mean) / baseline_mean\n", "recovery_pct_of_baseline <- 100 * post_reversal_mean / baseline_mean\n", "\n", "cat(\"KEY STATISTICS FOR\", discovery_group, \":\\n\\n\")\n", "cat(\"  Baseline (Pre-Policy) Mean:\", format(round(baseline_mean, 0), big.mark = \",\"), \"views/post\\n\")\n", "cat(\"  Trough (During Policy) Mean:\", format(round(trough_mean, 0), big.mark = \",\"), \"views/post\\n\")\n", "cat(\"  Post-Reversal Mean:\", format(round(post_reversal_mean, 0), big.mark = \",\"), \"views/post\\n\\n\")\n", "cat(\"  Decline from Baseline:\", sprintf(\"%.1f%%\", decline_from_baseline), \"\\n\")\n", "cat(\"  Recovery as % of Baseline:\", sprintf(\"%.1f%%\", recovery_pct_of_baseline), \"\\n\\n\")\n", "\n", "cat(\"BREAKPOINT SUMMARY:\\n\")\n", "cat(\"  T1 (Implementation):\", as.character(T1), \"\\n\")\n", "if (!is.null(T2)) cat(\"  T2 (Adjustment):\", as.character(T2), \"\\n\")\n", "if (!is.null(T3)) cat(\"  T3 (Reversal):\", as.character(T3), \"\\n\")\n", "cat(\"\\n\")\n", "\n", "# ============================================================================\n", "# OUTPUT FILES SUMMARY\n", "# ============================================================================\n", "\n", "cat(\"\\n\")\n", "cat(rep(\"=\", 80), \"\\n\", sep = \"\")\n", "cat(\"OUTPUT FILES PRODUCED (Aligned with Working Paper)\\n\")\n", "cat(rep(\"=\", 80), \"\\n\\n\", sep = \"\")\n", "\n", "cat(\"TABLES:\\n\")\n", "cat(\"  \u2022 RQ1_Table2_account_post_counts.csv  \u2192 Working Paper Table 2\\n\")\n", "cat(\"  \u2022 RQ1_Table3_engagement_stats.csv     \u2192 Working Paper Table 3\\n\")\n", "cat(\"  \u2022 RQ1_Table4_breakpoints.csv          \u2192 Working Paper Table 4\\n\")\n", "cat(\"  \u2022 RQ1_Table5_reach_by_phase.csv       \u2192 Working Paper Table 5\\n\")\n", "cat(\"  \u2022 RQ1_Table6_engagement_by_phase.csv  \u2192 Working Paper Table 6\\n\")\n", "cat(\"  \u2022 RQ1_Table7_validation.csv           \u2192 Working Paper Table 7\\n\")\n", "cat(\"  \u2022 RQ1_Table8_cross_group.csv          \u2192 Working Paper Table 8\\n\")\n", "cat(\"  \u2022 RQ1_Table9_pairwise.csv             \u2192 Working Paper Table 9\\n\")\n", "cat(\"  \u2022 RQ1_Table10_perpost_vs_total.csv    \u2192 Working Paper Table 10\\n\\n\")\n", "\n", "cat(\"FIGURES:\\n\")\n", "cat(\"  \u2022 RQ1_Figure1_timeseries.png  \u2192 Working Paper Figure 1\\n\")\n", "cat(\"  \u2022 RQ1_Figure2_discovery.png   \u2192 Working Paper Figure 2\\n\")\n", "cat(\"  \u2022 RQ1_Figure3_faceted.png     \u2192 Working Paper Figure 3\\n\\n\")\n", "\n", "# Save complete results object\n", "results_summary <- list(\n", "  analysis_date = Sys.time(),\n", "  data_file = weekly_file,\n", "  model_type = MODEL_TYPE,\n", "  discovery_group = discovery_group,\n", "  validation_groups = validation_groups,\n", "  breakpoints = FINAL_BREAKPOINTS,\n", "  table2 = table2,\n", "  table3 = table3_stats,\n", "  table4 = table4_data,\n", "  table5 = table5_stats,\n", "  table6 = table6_engagement,\n", "  table7 = validation_results,\n", "  table8 = table8_data,\n", "  table9 = table9_df,\n", "  table10 = table10_data,\n", "  key_findings = list(\n", "    baseline_mean = baseline_mean,\n", "    trough_mean = trough_mean,\n", "    post_reversal_mean = post_reversal_mean,\n", "    decline_pct = decline_from_baseline,\n", "    recovery_pct_of_baseline = recovery_pct_of_baseline\n", "  )\n", ")\n", "\n", "saveRDS(results_summary, \"RQ1_results_summary.rds\")\n", "cat(\"Complete results saved to: RQ1_results_summary.rds\\n\")\n", "\n", "cat(\"\\n=== RQ1 Analysis Complete ===\\n\")"], "id": "48a7f64e-672d-496e-bdbe-737ba8db382d", "cell_type": "code", "outputs": [{"output_type": "stream", "name": "stderr", "text": ["[NOTICE] 8 output(s) filtered out"]}]}], "nbformat": 4}